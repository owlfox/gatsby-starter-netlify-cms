Chapter 12. Languages
There are many programming languages, as well as compilers and runtimes to execute them, and the way each language is executed affects how it can be traced. This chapter explains such differences and will help you find ways to trace any given language.

Learning Objectives:

Understand compiled language instrumentation (e.g.: C)

Understand JIT compiled language instrumentation (e.g.: Java, Node.js)

Understand interpreted language instrumentation (e.g.: bash shell)

Trace function calls, arguments, return value, and latency when possible

Trace the user-level stack trace in a given language

This chapter begins by summarizing programming language implementations, then uses a few languages as examples: C for compiled languages, Java for a JIT-compiled language, and bash shell scripting for a fully interpreted language. For each, I cover how to find function names (symbols), function arguments, and how to investigate and trace stack traces. I have included notes for tracing other languages at the end of this chapter: JavaScript (Node.js), C++, and Golang.

Whatever your language of interest, this chapter should give you a head start in instrumenting it and understanding the challenges and solutions that have worked for other languages.

12.1 BACKGROUND
To understand how to instrument a given language, you need to examine how it is converted into machine code for execution. This isn’t usually an attribute of the language, but rather an attribute of how the language is implemented. Java, for example, is not a JIT-compiled language: Java is just a language. The commonly used JVM runtime from OracleJDK or OpenJDK executes Java methods with a pipeline that moves from interpretation to JIT compilation, but that is an attribute of the JVM. The JVM itself is also compiled C++ code, which runs functions such as class loading and garbage collection. In a fully instrumented Java application, you may encounter code that is compiled (C++ JVM functions), interpreted (Java methods), and JIT compiled (Java methods)—and there are differences in how each should be instrumented. Other languages have separate implementations of compilers and interpreters, and you need to know which is being used to understand how to trace it.

Put simply: if your task is to trace language X, your first question should be, what is the thing we are currently using to run X, and how does it work? Is it a compiler, JIT compiler, interpreter, animal, vegetable, or mineral?

This section provides general advice for tracing any language with BPF, by classifying language implementations by how they generate machine code: compiled, JIT compiled, or interpreted. Some implementations (e.g., the JVM) support multiple techniques.

12.1.1 Compiled
Examples of languages that are commonly compiled include C, C++, Golang, Rust, Pascal, Fortran, and COBOL.

For compiled languages, functions are compiled into machine code and stored in an executable binary, typically the ELF format, with the following attributes:

For user-level software, symbol tables are included in the ELF binary file for mapping addresses to function and object names. These addresses do not move during execution, so the symbol table can be read at any time for correct mappings. Kernel-level software differs as it has its own dynamic symbol table in /proc/kallsyms, which can grow as modules are loaded.

Function arguments and their return values are stored in registers and stack offsets. Their location usually follows a standard calling convention for each processor type; however, some compiled languages (e.g., Golang) use different conventions, and some (e.g., V8 built-ins) use no convention at all.

The frame pointer register (RBP on x86_64) can be walked to reveal the stack trace, if the compiler initializes it in function prologues. Compilers often instead reuse it as a general purpose register (a performance optimization for register-limited processors). A side effect is that it breaks frame pointer–based stack walking.

Compiled languages are usually easy to trace, using uprobes for user-level software and kprobes for kernel-level software. There are numerous examples throughout this book.

When approaching compiled software, check whether the symbol tables are present (e.g., using nm(1), objdump(1), or readelf(1)). If they are not, check whether a debuginfo package is available for the software, which can provide the missing symbols. If that, too, is a dead end, check the compiler and build software to see why the symbols are missing in the first place: they may be stripped using strip(1). One fix is to recompile the software without calling strip(1).

Also check whether frame pointer-based stack walking is working. This is the current default for walking user-space stacks via BPF, and if it is not working, the software may need to be recompiled with a compiler flag to honor the frame pointer (e.g., gcc -fno-omit-frame-pointer). If this is infeasible, other stack-walking techniques can be explored, such as last branch record (LBR),1 DWARF, user-level ORC, and BTF. There is still BPF tooling work needed to make use of these, discussed in Chapter 2.

1 There is not currently support for LBR in BPF or its front ends, but we intend to add it. perf(1) currently supports it with --call-graph lbr.

12.1.2 JIT Compiled
Examples of languages that are commonly JIT compiled include Java, JavaScript, Julia, .Net., and Smalltalk.

JIT compiled languages compile into bytecode, which is then compiled into machine code at runtime, often with feedback from runtime operation to direct compiler optimization. They have the following attributes (discussing user level only):

Because functions are compiled on the fly, there is no pre-built symbol table. The mappings are usually stored in memory of the JIT runtime, and used for purposes such as printing exception stacks. These mappings may also change, as the runtime may recompile and move functions around.

Function arguments and return values may or may not follow a standard calling convention.

The JIT runtime may or may not honor the frame pointer register, so frame pointer–based stack walking may work, or it may be broken (in which case you would see the stack trace ending abruptly with a bogus address). The runtime usually has a way to walk its own stack for an exception handler to print the stack trace during errors.

Tracing JIT-compiled languages is difficult. There is no symbol table on the binary since it is dynamic and in memory. Some applications provide supplemental symbol files for the JIT mappings (/tmp/perf-PID.map); however, these cannot be used with uprobes for two reasons:

The compiler may move uprobe-instrumented functions in memory without informing the kernel. When the instrumentation is no longer needed, the kernel reverts the instructions back to normal, but it is now writing to the wrong location and will corrupt user-space memory.2

2 I’ve asked the JVM team for a way to pause the c2 compiler so that functions stop moving during uprobe tracing.

uprobes are inode based and require a file location to work, whereas the JIT functions may be stored in anonymous private mappings.3

3 Along with others, I have been looking into how to remove this limitation from the kernel.

Tracing compiled functions may be possible if the runtime provides USDT probes for each function, although this technique usually incurs high overhead, whether it is enabled or not. A more efficient approach is to instrument selected points with dynamic USDT. (USDT and dynamic USDT were introduced in Chapter 2.) USDT probes also provide a solution for instrumenting function arguments and return values as arguments to those probes.

If stack traces from BPF already work, supplemental symbol files can be used to translate them into the function names. For a runtime that doesn’t support USDT, this provides one path for visibility into running JIT functions: stack traces can be collected on syscalls, kernel events, and via timed profiling, revealing the JIT functions that are running. This may be the easiest way you can get JIT function visibility to work, and can help solve many problem types.

If stack traces do not work, check whether the runtime supports frame pointers with an option or whether LBR can be used. If these are dead ends, there are a number of other ways to fix stack traces, although these may require significant engineering work. One way is to modify the runtime compiler to preserve the frame pointer. Another is to add USDT probes that use the language’s own means of getting the call stack, and providing this as a string argument. Yet another way is to signal the process from BPF and have a user-space helper write a stack trace to memory that BPF can read, as Facebook has implemented for hhvm [133].

Java is discussed later in this chapter as an example of how these techniques work in practice.

12.1.3 Interpreted
Examples of languages that are commonly interpreted include the bash shell, Perl, Python, and Ruby. There are also languages that commonly use interpretation as a stage before JIT compilation—for example, Java and JavaScript. The analysis of those staged languages during their interpretation stage is similar to analysis of languages that use only interpretation.

Interpreted language runtimes do not compile the program functions to machine code but instead parse and execute the program using their own built-in routines. They have the following attributes:

The binary symbol table shows interpreter internals but no functions from the user-supplied program. The functions are likely stored in a memory table that is specific to the interpreter implementation and maps to interpreter objects.

Function arguments and return values are processed by the interpreter. They are likely passed around by interpreter function calls and may be bundled as interpreter objects and rather than simple ints and strings.

If the interpreter itself is compiled to honor the frame pointer, frame pointer stack walking will work, but it will show only the interpreter internals with no function name context from the user-supplied program that is running. The program stack is likely known by the interpreter and printed for exception stacks but stored in a custom data structure.

USDT probes may exist to show the start and end of function calls, with the function name and arguments as arguments to the USDT probe. For example, the Ruby runtime has built-in USDT probes in the interpreter. While this provides a way to trace function calls, it can come with high overhead: it usually means instrumenting all function calls, and then filtering on the name for the functions of interest. If there is a dynamic USDT library for the language runtime, it can be used to insert custom USDT probes only in the functions of interest, rather than tracing all functions and then filtering. (See Chapter 2 for an introduction to dynamic USDT.) For example, the ruby-static-tracing package provides this for Ruby.

If the runtime does not have built-in USDT probes, and no package provides runtime USDT support (such as libstapsdt/libusdt), its interpreter functions can be traced using uprobes and details such as function names and arguments can be fetched. They may be stored as interpreter objects and require some struct navigation to parse.

Stack traces may be very difficult to tease out of the interpreter’s memory. One approach, albeit one with high overhead, is to trace all function calls and returns in BPF and construct a synthetic stack for each thread in BPF memory that can be read when needed. As with JIT-compiled languages, there may be other ways to add stack trace support, including via custom USDT probes and the runtime’s own method for fetching a stack (as with ruby’s “caller” built-in, or an exception method), or with a BPF signal to a user-space helper.

12.1.4 BPF Capabilities
The target capabilities for tracing a language with BPF are to answer these questions:

What functions are called?

What are the arguments to a function?

What is the return value of a function? Did it error?

What is code path (stack trace) that led to any event?

What is the duration of a function? As a histogram?

How many of these questions can be answered with BPF depends on the language implementation. Many language implementations come with custom debuggers that can answer the first four of these questions easily, so you might wonder why we even need BPF for this. A primary reason is to trace multiple layers of the software stack in one tool. Instead of examining disk I/O or page faults with kernel context alone, you can trace them along with the user-level code path responsible, and with application context: which user requests led to how much disk I/O or page faults, etc. In many cases, kernel events can identify and quantify an issue, but it’s the user-level code that shows how to fix it.

For some languages (e.g., Java), showing which stack trace led to an event is easier to get working than tracing its function/method calls. Combined with the numerous other kernel events that BPF can instrument, stack traces can accomplish much. You can see which application code paths led to disk I/O, page faults, and other resource usage; you can see which code paths led to the thread blocking and leaving the CPU; and you can use timed sampling to profile CPU usage and build CPU flame graphs.

12.1.5 Strategy
Here is a suggested overall strategy you can follow for the analysis of a language:

Determine how the language is executed. For the software that runs it, is it using compilation to binaries, JIT compilation on the fly, interpretation, or a mix of these? This directs your approach as discussed in this chapter.

Browse the tools and one-liners in this chapter to understand the kinds of things that are possible for each language type.

Do an internet search for “[e]BPF language”, “BCC language”, and “bpftrace language” to see if there are already tools and know-how for analyzing the language with BPF.

Check if the language software has USDT probes and if they are enabled in the distributed binaries (or if you need to recompile to enable them). These are a stable interface and preferable to use. If the language software does not have USDT probes, consider adding them. Most language software is open source.

Write a sample program to instrument. Call a function with a known name a known number of times, and with known latency (explicit sleep). This can be used to check if your analysis tools are working, by checking that they identify all these knowns correctly.

For user-level software, use uprobes to inspect the language execution at the native level. For kernel-level software, use kprobes.

The sections that follow are longer discussions on three example languages: C for compiled, Java for JIT compiled, and the bash shell for interpreted languages.

12.1.6 BPF Tools
The BPF tools covered in this chapter are pictured in Figure 12-1.


Figure 12-1 BPF tools for language analysis

These tools cover C, Java, and bash.

12.2 C
C is the easiest of the languages to trace.

For kernel-level C, the kernel has its own symbol table, and most distributions honor the frame pointer for their kernel builds (CONFIG_FRAME_POINTER=y). This makes tracing kernel functions with kprobes straightforward: the functions can be seen and traced, arguments follow the processor ABI, and stack traces can be fetched. At least, most functions can be seen and traced: exceptions include inlined functions, and those marked on a tracing blacklist by the kernel as unsafe to instrument.

For user-level C, if a compiled binary does not strip its symbol tables, and does not omit the frame pointer, then tracing is straightforward with uprobes: functions can be seen and traced, arguments follow the processor ABI, and stack traces can be fetched. Unfortunately, many binaries do strip their symbol tables and compilers do omit the frame pointer, meaning you need to recompile them or find other ways to read symbols and stacks.

USDT probes can be used in C programs for static instrumentation. Some C libraries, including libc, provide USDT probes by default.

This section discusses C function symbols, C stack traces, C function tracing, C function offset tracing, C USDT, and C one-liners. Table 12-1 lists tools for instrumenting custom C code that have already been covered in other chapters.

C++ tracing is similar to C and is summarized in Section 12.5.

Table 12-1 C-Related Tools

Tool

Source

Target

Description

Chapter

funccount

BCC

Functions

Count function calls

4

stackcount

BCC

Stacks

Count native stacks to events

4

trace

BCC

Functions

Print function calls and returns with details

4

argdist

BCC

Functions

Summarize function arguments or return value

4

bpftrace

BT

All

Custom function and stack instrumentation

5

12.2.1 C Function Symbols
Function symbols can be read from the ELF symbol tables. readelf(1) can be used to check if these are present. For example, here are symbols in a microbenchmark program:

Click here to view code image


$ readelf -s bench1

Symbol table '.dynsym' contains 10 entries:
   Num:    Value         Size Type    Bind   Vis    Ndx Name
     0: 0000000000000000    0 NOTYPE LOCAL  DEFAULT UND
     1: 0000000000000000    0 NOTYPE WEAK   DEFAULT UND _ITM_deregisterTMCloneTab
     2: 0000000000000000    0 FUNC   GLOBAL DEFAULT UND puts@GLIBC_2.2.5 (2)
     3: 0000000000000000    0 FUNC   GLOBAL DEFAULT UND __libc_start_main@GLIBC...
     4: 0000000000000000    0 NOTYPE WEAK   DEFAULT UND __gmon_start__
     5: 0000000000000000    0 FUNC   GLOBAL DEFAULT UND malloc@GLIBC_2.2.5 (2)
     6: 0000000000000000    0 FUNC   GLOBAL DEFAULT UND atoi@GLIBC_2.2.5 (2)
     7: 0000000000000000    0 FUNC   GLOBAL DEFAULT UND exit@GLIBC_2.2.5 (2)
     8: 0000000000000000    0 NOTYPE WEAK   DEFAULT UND _ITM_registerTMCloneTable
     9: 0000000000000000    0 FUNC   WEAK   DEFAULT UND __cxa_finalize@GLIBC_2.2.5 (2)

Symbol table '.symtab' contains 66 entries:
   Num:    Value          Size Type    Bind   Vis      Ndx Name
     0: 0000000000000000     0 NOTYPE  LOCAL  DEFAULT  UND
     1: 0000000000000238     0 SECTION LOCAL  DEFAULT    1
     2: 0000000000000254     0 SECTION LOCAL  DEFAULT    2
     3: 0000000000000274     0 SECTION LOCAL  DEFAULT    3
     4: 0000000000000298     0 SECTION LOCAL  DEFAULT    4
     [...]
    61: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND exit@@GLIBC_2.2.5
    62: 0000000000201010     0 OBJECT  GLOBAL HIDDEN    23 __TMC_END__
    63: 0000000000000000     0 NOTYPE  WEAK   DEFAULT  UND _ITM_registerTMCloneTable
    64: 0000000000000000     0 FUNC    WEAK   DEFAULT  UND __cxa_finalize@@GLIBC_2.2
    65: 0000000000000590     0 FUNC    GLOBAL DEFAULT   11 _init

The symbol table, “.symtab”, has dozens of entries (truncated here). There is an additional symbol table used for dynamic linking, “.dynsym”, which has six function symbols.

Now consider these symbol tables after the binary has been run through strip(1), which is often the case for many packaged binaries:

Click here to view code image


$ readelf -s bench1

Symbol table '.dynsym' contains 10 entries:
   Num:    Value          Size Type    Bind   Vis      Ndx Name
     0: 0000000000000000     0 NOTYPE  LOCAL  DEFAULT  UND
     1: 0000000000000000     0 NOTYPE  WEAK   DEFAULT  UND _ITM_deregisterTMCloneTab
     2: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND puts@GLIBC_2.2.5 (2)
     3: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND __libc_start_main@GLIBC...
     4: 0000000000000000     0 NOTYPE  WEAK   DEFAULT  UND __gmon_start__
     5: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND malloc@GLIBC_2.2.5 (2)
     6: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND atoi@GLIBC_2.2.5 (2)
     7: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND exit@GLIBC_2.2.5 (2)
     8: 0000000000000000     0 NOTYPE  WEAK   DEFAULT  UND _ITM_registerTMCloneTable
     9: 0000000000000000     0 FUNC    WEAK   DEFAULT  UND __cxa_finalize@GLIBC_2....

strip(1) removes the .symtab symbol table but leaves the .dynsym table. .dynsym contains external global symbols that are called, and .symtab contains the same plus local symbols from the application. Without .symtab, there are still some symbols in the binary for library calls, but it may be missing the most interesting ones.

Statically compiled applications that are stripped may lose all symbols, since they had all been placed in the .symtab that is removed.

There are at least two ways to fix this:

Remove strip(1) from the software build process and recompile the software.

Use a different source of symbols: DWARF debuginfo or BTF.

Debuginfo for software packages is sometimes available as a software package with a -dbg, -dbgsym, or -debuginfo extension. It is supported by the perf(1) command, BCC, and bpftrace.

Debuginfo
Debuginfo files may have the same name as the binary with a “.debuginfo” extension, or use a build ID unique checksum for the filename and reside under /usr/lib/debug/.build-id or a user version of this. For the latter, the build ID is stored in the binary ELF notes section, and can be seen using readelf -n.

As an example, this system has openjdk-11-jre and openjdk-11-dbg packages installed, providing both libjvm.so and libjvm.debuginfo files. Here are the symbol counts for each:

Click here to view code image


$ readelf -s /usr/lib/jvm/.../libjvm.so | wc -l
456
$ readelf -s /usr/lib/jvm/.../libjvm.debuginfo | wc -l
52299

The stripped version has 456 symbols, and the debuginfo version has 52,299.

Lightweight Debuginfo
While it might seem worthwhile to always install the debuginfo file, it comes at a file size cost: the debuginfo file is 222 Mbytes, compared to 17 Mbytes for libjvm.so. Much of this size is not symbol information but other debuginfo sections. The size of the symbol information can be checked using readelf(1):

Click here to view code image


$ readelf -S libjvm.debuginfo
There are 39 section headers, starting at offset 0xdd40468:

Section Headers:
  [Nr] Name              Type             Address           Offset
       Size              EntSize          Flags  Link  Info  Align
[...]
  [36] .symtab           SYMTAB           0000000000000000  0da07530
       00000000001326c0  0000000000000018          37   51845     8
[...]

This shows the size of .symtab is only 1.2 Mbytes. For comparison, the openjdk package that provided libjvm.so is 175 Mbytes.

If the full debuginfo size is a problem, you could explore stripping down the debuginfo file. The following commands use objcopy(1) to strip out the other debuginfo sections (which begin with “.debug_”) to create a lightweight debuginfo file. This can be used as a debuginfo replacement that contains symbols, or it can also be reattached to the binary using eu-unstrip(1). Example commands:

Click here to view code image


$ objcopy -R.debug_\* libjvm.debuginfo libjvm.symtab
$ eu-unstrip -o libjvm.new.so libjvm.so libjvm.symtab
$ ls -lh libjvm.orig.so libjvm.debuginfo libjvm.symtab libjvm.new.so
-rwxr-xr-x 1 root root 222M Nov 13 04:53 libjvm.debuginfo*
-rwxr-xr-x 1 root root  20M Feb 16 19:02 libjvm.new.so*
-rw-r--r-- 1 root root  17M Nov 13 04:53 libjvm.so
-rwxr-xr-x 1 root root 3.3M Feb 16 19:00 libjvm.symtab*
$ readelf -s libjvm.new.so | wc -l
52748

The new libjvm.new.so is only 20 Mbytes and contains all the symbols. Note that this is a proof of concept technique I developed for this book, and has not yet had production testing.

BTF
In the future, the BPF Type Format (BTF) may provide another lightweight source of debuginfo, and one that was designed for use by BPF. So far BTF is kernel only: work has not yet began on a user-level version. See Chapter 2 for BTF.

Using bpftrace
Apart from using readelf(1), bpftrace can also list symbols from a binary by matching which uprobes are available to instrument4:

4 Matheus Marchini developed this feature after reviewing a draft of this chapter and realizing it was needed.

Click here to view code image


# bpftrace -l 'uprobe:/bin/bash'
uprobe:/bin/bash:rl_old_menu_complete
uprobe:/bin/bash:maybe_make_export_env
uprobe:/bin/bash:initialize_shell_builtins
uprobe:/bin/bash:extglob_pattern_p
uprobe:/bin/bash:dispose_cond_node
[...]

Wildcards can also be used:

Click here to view code image


# bpftrace -l 'uprobe:/bin/bash:read*'
uprobe:/bin/bash:reader_loop
uprobe:/bin/bash:read_octal
uprobe:/bin/bash:readline_internal_char
uprobe:/bin/bash:readonly_builtin
uprobe:/bin/bash:read_tty_modified
[...]

Section 12.2.3 instruments one of these as an example.

12.2.2 C Stack Traces
BPF currently supports frame pointer–based stack walking. For this to work, the software must be compiled to use the frame pointer register. For the gcc compiler, this is the -fno-omit-frame-pointer option. In the future, BPF may support other types of stack walking as well.

Since BPF is programmable, I was able to code a frame pointer stack walker in pure BPF before real support was added [134]. Alexei Starovoitov added official support with a new map type, BPF_MAP_TYPE_STACK_TRACE, and a helper, bpf_get_stackid(). The helper returns a unique ID for the stack, and the map stores the contents of the stack. This minimizes storage for stack traces, since duplicates reuse the same ID and storage.

From bpftrace, stacks are available via the ustack and kstack built-ins, for user-level and kernel stacks. Here is an example of tracing the bash shell, which is a large C program, and printing the stack trace that led to a read of file descriptor 0 (STDIN):

Click here to view code image


# bpftrace -e 't:syscalls:sys_enter_read /comm == "bash" &&
    args->fd == 0/ { @[ustack] = count(); }'
Attaching 1 probe...
^C

@[
    read+16
    0x6c63004344006d
]: 7

This stack is actually broken: after the read() function is a hexadecimal number that does not look like an address. (pmap(1) can be used to check the address space mappings for a PID to see if it is in a range or not; in this case, it isn’t.)

Now a bash shell that’s been recompiled with -fno-omit-frame-pointer:

Click here to view code image


# bpftrace -e 't:syscalls:sys_enter_read /comm == "bash" &&
    args->fd == 0/ { @[ustack] = count(); }'
Attaching 1 probe...
^C

@[
    read+16
    rl_read_key+307
    readline_internal_char+155
    readline_internal_charloop+22
    readline_internal+23
    readline+91
    yy_readline_get+142
    yy_readline_get+412
    yy_getc+13
    shell_getc+464
    read_token+250
    yylex+184
    yyparse+776
    parse_command+122
    read_command+203
    reader_loop+377
    main+2355
    __libc_start_main+240
    0xa9de258d4c544155
]: 30

The stack trace is now visible. It is printed top-down from leaf to root. Put differently, top-down is also child to parent to grandparent and so on.

This example shows the shell reading from STDIN via readline() functions, in a read_command() code path. It is the bash shell reading input.

The bottom of the stack is another bogus address after __libc_start_main. The problem is that the stack has now walked into a system library, libc, and that has been compiled without the frame pointer.

See Section 2.4 in Chapter 2 for more about how BPF walks stacks and future work.

12.2.3 C Function Tracing
Functions can be traced using kprobes and kretprobes for kernel functions, and uprobes and uretprobes for user-level functions. These technologies were introduced in Chapter 2, and Chapter 5 covered how to use them from bpftrace. There are many examples of their use in this book.

As one example for this section: the following traces the readline() function, which is usually included in the bash shell. Since this is user-level software, it can be traced with uprobes. Here is the function signature:

char * readline(char *prompt)
It takes a string argument, the prompt, and also returns a string. Using a uprobe to trace the prompt argument, which is available as the arg0 built-in:

Click here to view code image


# bpftrace -e 'uprobe:/bin/bash:readline { printf("readline: %s\n", str(arg0)); }'
Attaching 1 probe...
readline: bgregg:~/Build/bpftrace/tools>
readline: bgregg:~/Build/bpftrace/tools>

This showed the prompt ($PS1) printed by a shell in another window.

Now tracing the return value and showing it as a string, using a uretprobe:

Click here to view code image


# bpftrace -e 'uretprobe:/bin/bash:readline { printf("readline: %s\n",
    str(retval)); }'
Attaching 1 probe...
readline: date
readline: echo hello reader

This showed the input I was typing in another window.

Apart from the main binary, shared libraries can also be traced by replacing the “/bin/bash” path in the probe with the path to the library. Some Linux distributions5 build bash so that readline is called via libreadline, and the above one-liners will fail as the readline() symbol is not in /bin/bash. They may be traced using the path to libreadline, for example:

5 For example, Arch Linux.

Click here to view code image


# bpftrace -e 'uretprobe:/usr/lib/libreadline.so.8:readline {
    printf("readline: %s\n", str(retval)); }'

12.2.4 C Function Offset Tracing
There may be times when you would like to trace an arbitrary offset within a function rather than just its start and return points. Apart from greater visibility to a function’s code flow, by inspecting registers you could also determine the contents of local variables.

uprobes and kprobes support tracing at arbitrary offsets, as does BCC’s attach_uprobe() and attach_kprobe() from its Python API. However, this capability is not yet exposed via BCC tools such as trace(8) and funccount(8), nor is it available yet in bpftrace. It should be straightforward to add to these tools. The difficulty will be adding it safely. uprobes does not check for instruction alignment, so tracing the wrong address (e.g., midway through a multi-byte instruction) will corrupt the instructions in the target program, causing it to fail in unpredictable ways. Other tracers, such as perf(1), use debuginfo to check for instruction alignment.

12.2.5 C USDT
USDT probes can be added to C programs to provide static instrumentation: a reliable API for tracing tools to use. Some programs and libraries already provide USDT probes, for example, listing libc USDT probes using bpftrace:

Click here to view code image


# bpftrace -l 'usdt:/lib/x86_64-linux-gnu/libc-2.27.so'
usdt:/lib/x86_64-linux-gnu/libc-2.27.so:libc:setjmp
usdt:/lib/x86_64-linux-gnu/libc-2.27.so:libc:longjmp
usdt:/lib/x86_64-linux-gnu/libc-2.27.so:libc:longjmp_target
usdt:/lib/x86_64-linux-gnu/libc-2.27.so:libc:memory_mallopt_arena_max
usdt:/lib/x86_64-linux-gnu/libc-2.27.so:libc:memory_mallopt_arena_test
usdt:/lib/x86_64-linux-gnu/libc-2.27.so:libc:memory_tunable_tcache_max_bytes
[...]

There are different libraries that provide USDT instrumentation, including systemtap-sdt-dev and Facebook’s Folly. For an example of adding USDT probes to a C program, see Chapter 2.

12.2.6 C One-Liners
These sections show BCC and bpftrace one-liners. Where possible, the same one-liner is implemented using both BCC and bpftrace.

BCC
Count kernel function calls starting with “attach”:

funccount 'attach*'
Count function calls starting with “a” from a binary (e.g., /bin/bash):

funccount '/bin/bash:a*'
Count function calls starting with “a” from a library (e.g., libc.so.6):

Click here to view code image

funccount '/lib/x86_64-linux-gnu/libc.so.6:a*'
Trace a function and its argument (e.g., bash readline()):

Click here to view code image

trace '/bin/bash:readline "%s", arg1'
Trace a function and its return value (e.g., bash readline()):

Click here to view code image

trace 'r:/bin/bash:readline "%s", retval'
Trace a library function and its argument (e.g., libc fopen()):

Click here to view code image

trace '/lib/x86_64-linux-gnu/libc.so.6:fopen "%s", arg1'
Count a library function return value (e.g., libc fopen()):

Click here to view code image

argdist -C 'r:/lib/x86_64-linux-gnu/libc.so.6:fopen():int:$retval'
Count a user-level stack trace on a function (e.g., bash readline()):

Click here to view code image

stackcount -U '/bin/bash:readline'
Sample user stacks at 49 Hertz:

profile -U -F 49
bpftrace
Count kernel function calls starting with “attach”:

Click here to view code image

bpftrace -e 'kprobe:attach* { @[probe] = count(); }'
Count function calls starting with “a” from a binary (e.g., /bin/bash):

Click here to view code image

bpftrace -e 'uprobe:/bin/bash:a* { @[probe] = count(); }'
Count function calls starting with “a” from a library (e.g., libc.so.6):

Click here to view code image

bpftrace -e 'u:/lib/x86_64-linux-gnu/libc.so.6:a* { @[probe] = count(); }'
Trace a function and its argument (e.g., bash readline()):

Click here to view code image

bpftrace -e 'u:/bin/bash:readline { printf("prompt: %s\n", str(arg0)); }'
Trace a function and its return value (e.g., bash readline()):

Click here to view code image

bpftrace -e 'ur:/bin/bash:readline { printf("read: %s\n", str(retval)); }'
Trace a library function and its argument (e.g., libc fopen()):

Click here to view code image

bpftrace -e 'u:/lib/x86_64-linux-gnu/libc.so.6:fopen { printf("opening: %s\n",
    str(arg0)); }'
Count a library function return value (e.g., libc fopen()):

Click here to view code image

bpftrace -e 'ur:/lib/x86_64-linux-gnu/libc.so.6:fopen { @[retval] = count(); }'
Count a user-level stack trace on a function (e.g., bash readline()):

Click here to view code image

bpftrace -e 'u:/bin/bash:readline { @[ustack] = count(); }'
Sample user stacks at 49 Hertz:

Click here to view code image

bpftrace -e 'profile:hz:49 { @[ustack] = count(); }'
12.3 JAVA
Java is a complex target to trace. The Java virtual machine (JVM) executes Java methods by compiling them to bytecode and then running them in an interpreter. Then, when they have exceeded an execution threshold (-XX:CompileThreshold), they are JIT compiled into native instructions. The JVM will also profile method execution and recompile methods to further improve their performance, changing their memory location on the fly. The JVM includes libraries written in C++ for compilation, thread management, and garbage collection. The most commonly used JVM is called HotSpot, originally developed by Sun Microsystems.

The C++ components of the JVM (libjvm) can be instrumented as with compiled languages, covered in the previous section. The JVM comes with many USDT probes to make tracing JVM internals easier. These USDT probes can also instrument Java methods, but they come with challenges that will be discussed in this section.

This section begins with a brief look at libjvm C++ tracing and then discusses Java thread names, Java method symbols, Java stack traces, Java USDT probes, and Java one-liners. The Java-related tools listed in Table 12-2 are also covered.

Table 12-2 Java-Related Tools

Tool

Source

Target

Description

jnistacks

Book

libjvm

Show JNI consumers by object stack trace

profile

BCC

CPUs

Timed sampling of stack traces, including Java methods

offcputime

BCC

Sched

Off-CPU time with stack traces, including Java methods

stackcount

BCC

Events

Show stacks traces for any given event

javastat

BCC

USDT

High-level language operation statistics

javathreads

Book

USDT

Trace thread start and stop events

javacalls

BCC/book

USDT

Count Java method calls

javaflow

BCC

USDT

Show Java method code flow

javagc

BCC

USDT

Trace Java garbage collections

javaobjnew

BCC

USDT

Count Java new object allocations

Some of these tools show Java methods, and to show their output on Netflix production servers would require redacting internal code, making the examples difficult to follow. Instead, I will demonstrate these on an open source Java game: freecol. The software for this game is complex and performance sensitive, making it a similar target to Netflix production code.6 The freecol website is: http://www.freecol.org.

6 At the SCaLE 2019 conference, I performed live BPF analysis of another complex Java game: Minecraft. While it has a similar analysis complexity to freecol and Netflix production applications, it is less suitable to analyze here as it is not open source.

12.3.1 libjvm Tracing
The JVM main library, libjvm, contains thousands of functions for running Java threads, loading classes, compiling methods, allocating memory, garbage collection, and more. These are mostly written in C++, and can be traced to provide different views of the running Java program.

As an example, I’ll trace all the Java native interface (JNI) functions using BCC’s funccount(8) (bpftrace can also be used):

Click here to view code image


# funccount '/usr/lib/jvm/java-11-openjdk-amd64/lib/server/libjvm.so:jni_*'
Tracing 235 functions
for "/usr/lib/jvm/java-11-openjdk-amd64/lib/server/libjvm.
so:jni_*"... Hit Ctrl-C to end.
^C
FUNC                                    COUNT
jni_GetObjectClass                          1
jni_SetLongArrayRegion                      2
jni_GetEnv                                 15
jni_SetLongField                           42
jni_NewWeakGlobalRef                       84
jni_FindClass                             168
jni_GetMethodID                           168
jni_NewObject                             168
jni_GetObjectField                        168
jni_ExceptionOccurred                     719
jni_CallStaticVoidMethod                 1144
jni_ExceptionCheck                       1186
jni_ReleasePrimitiveArrayCritical        3787
jni_GetPrimitiveArrayCritical            3787
Detaching...

This traced functions in libjvm.so matching “jni_*”, and found that the most frequent was jni_ GetPrimitiveArrayCritical(), called 3552 while tracing. The libjvm.so path was truncated in the output to prevent line wrapping.

libjvm Symbols
The libjvm.so that is usually packaged with the JDK has been stripped, which means that the local symbol table is not available and these JNI functions cannot be traced without extra steps. The status can be checked using file(1):

Click here to view code image


$ file /usr/lib/jvm/java-11-openjdk-amd64/lib/server/libjvm.orig.so
/usr/lib/jvm/java-11-openjdk-amd64/lib/server/libjvm.orig.so: ELF 64-bit LSB shared
object, x86-64, version 1 (GNU/Linux), dynamically linked,
BuildID[sha1]=f304ff36e44ce8a68a377cb07ed045f97aee4c2f, stripped

Possible solutions:

Build your own libjvm from source and do not use strip(1).

Install the JDK debuginfo package, if available, which BCC and bpftrace support.

Install the JDK debuginfo package and use elfutils unstrip(1) to add the symbol table back to libjvm.so (see the earlier “Debuginfo” section, under Section 12.2.1).

Use BTF, when available (covered in Chapter 2).

For this example, I used the second option.

12.3.2 jnistacks
As an example libjvm tool, jnistacks(8)7 counts stacks that led to the jni_NewObject() call seen in the previous output, and others starting with “jni_NewObject”. This will reveal which Java code paths, including Java methods, led to new JNI objects. Some example output:

7 Origin: I created it for this book on 8-Feb-2019.

Click here to view code image


# bpftrace --unsafe jnistacks.bt
Tracing jni_NewObject* calls... Ctrl-C to end.
^C
Running /usr/local/bin/jmaps to create Java symbol files in /tmp...
Fetching maps for all java processes...
Mapping PID 25522 (user bgregg):
wc(1):   8350  26012 518729 /tmp/perf-25522.map

[...]
@[
    jni_NewObject+0
    Lsun/awt/X11GraphicsConfig;::pGetBounds+171
    Ljava/awt/MouseInfo;::getPointerInfo+2048
    Lnet/sf/freecol/client/gui/plaf/FreeColButtonUI;::paint+1648
    Ljavax/swing/plaf/metal/MetalButtonUI;::update+232
    Ljavax/swing/JComponent;::paintComponent+672
    Ljavax/swing/JComponent;::paint+2208
    Ljavax/swing/JComponent;::paintChildren+1196
    Ljavax/swing/JComponent;::paint+2256
    Ljavax/swing/JComponent;::paintChildren+1196
    Ljavax/swing/JComponent;::paint+2256
    Ljavax/swing/JLayeredPane;::paint+2356
    Ljavax/swing/JComponent;::paintChildren+1196
    Ljavax/swing/JComponent;::paint+2256
    Ljavax/swing/JComponent;::paintToOffscreen+836
    Ljavax/swing/BufferStrategyPaintManager;::paint+3244
    Ljavax/swing/RepaintManager;::paint+1260
    Interpreter+5955
    Ljavax/swing/JComponent;::paintImmediately+3564
    Ljavax/swing/RepaintManager$4;::run+1684
    Ljavax/swing/RepaintManager$4;::run+132
    call_stub+138
    JavaCalls::call_helper(JavaValue*, methodHandle const&, JavaCallArguments*, Th...
    JVM_DoPrivileged+1600
    Ljava/security/AccessController;::doPrivileged+216
    Ljavax/swing/RepaintManager;::paintDirtyRegions+4572
    Ljavax/swing/RepaintManager;::paintDirtyRegions+660
    Ljavax/swing/RepaintManager;::prePaintDirtyRegions+1556
    Ljavax/swing/RepaintManager$ProcessingRunnable;::run+572
    Ljava/awt/EventQueue$4;::run+1100
    call_stub+138
    JavaCalls::call_helper(JavaValue*, methodHandle const&, JavaCallArguments*, Th...
]: 232

For brevity, only the last stack has been included here. It can be inspected from bottom to top to show the path to that call, or top-down to inspect ancestry. It looks like it begins with an event from a queue (EventQueue), then moves through paint methods, and finally calls sun.awt.X11GraphicsConfig::pGetBounds(), which is making the JNI call—I would guess because it needs to call an X11 graphics library.

Some Interpreter() frames are seen: this is Java executing methods using its interpreter, before they cross CompileThreshold and become natively compiled methods.

It is a little hard to read this stack since the Java symbols are class signatures. bpftrace does not yet support demangling them. The c++filt(1) tool does not currently support this version of Java class signatures either.8 To show how these should be demangled, this symbol:

8 Please feel free to fix bpftrace and c++filt(1).

Click here to view code image

Ljavax/swing/RepaintManager;::prePaintDirtyRegions+1556
should be:

Click here to view code image

javax.swing.RepaintManager::prePaintDirtyRegions()+1556
The source code to jnistacks(8) is:

Click here to view code image


#!/usr/local/bin/bpftrace

BEGIN
{
        printf("Tracing jni_NewObject* calls... Ctrl-C to end.\n");
}

uprobe:/usr/lib/jvm/java-11-openjdk-amd64/lib/server/libjvm.so:jni_NewObject*
{
        @[ustack] = count();
}

END
{
        $jmaps = "/usr/local/bin/jmaps";
        printf("\nRunning %s to create Java symbol files in /tmp...\n", $jmaps);
        system("%s", $jmaps);
}

The uprobe traces all calls from libjvm.so that begin with “jni_NewObject*”, and frequency counts the user stack trace.

The END clause runs an external program, jmaps, which sets up a supplemental Java method symbol file in /tmp. This uses the system() function, which requires the --unsafe command line argument, since the commands that system() runs cannot be verified by the BPF safety verifier.

The output from jmaps was included in the bpftrace output earlier. It is explained in Section 12.3.4. jmaps can be run externally and does not need to be in this bpftrace program (you can delete the END clause); however, the greater the time between its execution and when the symbol dump is used, the greater the chance for stale and mistranslated symbols. By including it in the bpftrace END clause, it is executed immediately before the stacks are printed out, minimizing the time between its collection and use.

12.3.3 Java Thread Names
The JVM allows custom names for each thread. If you try to match “java” as a process name, you may find no events since the threads are named something else. For example, using bpftrace:

Click here to view code image


# bpftrace -e 'profile:hz:99 /comm == "java"/ { @ = count(); }'
Attaching 1 probe...
^C
#

Now matching on the Java process ID and showing thread IDs and the comm built-in:

Click here to view code image


# bpftrace -e 'profile:hz:99 /pid == 16914/ { @[tid, comm] = count(); }'
Attaching 1 probe...
^C

@[16936, VM Periodic Tas]: 1
[...]
@[16931, Sweeper thread]: 4
@[16989, FreeColClient:b]: 4
@[21751, FreeColServer:A]: 7
@[21779, FreeColClient:b]: 18
@[21780, C2 CompilerThre]: 20
@[16944, AWT-XAWT]: 22
@[16930, C1 CompilerThre]: 24
@[16946, AWT-EventQueue-]: 51
@[16929, C2 CompilerThre]: 241

The comm built-in returns the thread (task) name, not the parent process name. This has the advantage of providing more context for the thread: the above profile shows that the C2 ComplierThread (name truncated) was consuming the most CPU while sampling. But this can also be confusing, since other tools including top(1) show the parent process name: “java”.9

9 In the future, we may add a bpf_get_current_pcomm() to the kernel to return the process name, which could be used in addition to the thread name. In bpftrace, this may be exposed as “pcomm.”

These thread names can be seen in /proc/PID/task/TID/comm. For example, using grep(1) to print them with filenames:

Click here to view code image


# grep . /proc/16914/task/*/comm
/proc/16914/task/16914/comm:java
[...]
/proc/16914/task/16959/comm:GC Thread#7
/proc/16914/task/16963/comm:G1 Conc#1
/proc/16914/task/16964/comm:FreeColClient:W
/proc/16914/task/16981/comm:FreeColClient:S
/proc/16914/task/16982/comm:TimerQueue
/proc/16914/task/16983/comm:Java Sound Even
/proc/16914/task/16985/comm:FreeColServer:S
/proc/16914/task/16989/comm:FreeColClient:b
/proc/16914/task/16990/comm:FreeColServer:-

The examples in the following sections match on the Java PID rather than the name “java”, and now you know why. There is an additional reason: USDT probes that use a semaphore require a PID so that bpftrace knows to set the semaphore for that PID. See Section 2.10.1 in Chapter 2 for more details on these semaphore probes.

12.3.4 Java Method Symbols
The open source perf-map-agent can be used to create supplemental symbol files containing the addresses of the complied Java methods [135]. This is necessary any time you are printing stack traces or addresses containing Java methods; otherwise, the addresses will be unknown. perf-map-agent uses the convention created by Linux perf(1) of writing a text file in /tmp/perf-PID.map with the following format [136]:

START SIZE symbolname
Here are some example symbols from a production Java application, where the symbol contains “sun” (just as an example):

Click here to view code image


$ grep sun /tmp/perf-3752.map
[...]
7f9ce1a04f60 80 Lsun/misc/FormattedFloatingDecimal;::getMantissa
7f9ce1a06d60 7e0 Lsun/reflect/GeneratedMethodAccessor579;::invoke
7f9ce1a08de0 80 Lsun/misc/FloatingDecimal$BinaryToASCIIBuffer;::isExceptional
7f9ce1a23fc0 140 Lsun/security/util/Cache;::newSoftMemoryCache
7f9ce1a243c0 120 Lsun/security/util/Cache;::<init>
7f9ce1a2a040 1e80 Lsun/security/util/DerInputBuffer;::getBigInteger
7f9ce1a2ccc0 980 Lsun/security/util/DisabledAlgorithmConstraints;::permits
7f9ce1a36c20 200 Lcom/sun/jersey/core/reflection/ReflectionHelper;::findMethodOnCl...
7f9ce1a3a360 6e0 Lsun/security/util/MemoryCache;::<init>
7f9ce1a523c0 760 Lcom/sun/jersey/core/reflection/AnnotatedMethod;::hasMethodAnnota...
7f9ce1a60b60 860 Lsun/reflect/GeneratedMethodAccessor682;::invoke
7f9ce1a68f20 320 Lsun/nio/ch/EPollSelectorImpl;::wakeup
[...]

perf-map-agent can be run on-demand, and attaches to a live Java process and dumps the symbol table. Note that this procedure that can generate some performance overhead during the symbol dump, and for large Java applications it can take more than one second of CPU time.

Since this is a snapshot of the symbol table, it will quickly become out of date as the Java compiler recompiles methods, which it may continue to do after the workload seems to have reached a steady state. The more time between the symbol snapshot and the BPF tool translating method symbols, the more chances for symbols to be stale and mistranslated. For busy production workloads with high rates of compilation, I do not trust Java symbol dumps that are more than 60 seconds old.

Section 12.3.5 provides an example of a stack trace without the perf-map-agent symbol table, then with it after jmaps was run.

Automation
You can automate these symbol dumps to minimize the time between their creation and use by a BPF tool. The perf-map-agent project contains software to automate this, and I’ve published my own program called jmaps [137]. jmaps finds all java processes (based on their process name) and dumps their symbol tables. An example of running jmaps on a 48-CPU production server:

Click here to view code image


# time ./jmaps
Fetching maps for all java processes...
Mapping PID 3495 (user www):
wc(1):  116736  351865 9829226 /tmp/perf-3495.map


real   0m10.495s
user   0m0.397s
sys    0m0.134s

This output includes various statistics: jmaps runs wc(1) on the final symbol dump, which shows it is 116,000 lines (symbols) and 9.4 Mbytes (9829226 bytes). I also ran it through time(1) to show how long it took: this is a busy Java application with 174 Gbytes of main memory, and it took 10.5 seconds to run. (Much of the CPU time involved is not seen by the user and sys statistics, as it was in the running JVM.)

For use with BCC, jmaps can be run immediately before the tool. For example:

./jmaps; trace -U '...'
This would invoke the trace(8) command immediately after jmaps completed, minimizing the time for symbols to become stale. For tools that collect a summary of stack traces (e.g., stackcount(8)), the tool itself could be modified to call jmaps immediately before printing the summary.

With bpftrace, jmaps can be run in a BEGIN clause for tools that use printf(), and an END clause for those that print map summaries. The previous jnistacks(8) tool was an example of the latter.

Other Techniques and Future Work
With these techniques reducing symbol churn, the perf-map-agent approach has served many environments well. However, other approaches may better solve the stale symbol table problem, and may be supported by BCC in the future. In summary:

Timestamped symbol logging: perf(1) supports this, and the software is in the Linux source.10 It currently involves always-on logging, which incurs some performance overhead. Ideally, it would not require always-on logging but instead could be enabled on demand at the start of a trace, and then when disabled it could take a full symbol table snapshot. This would allow the symbol state over time to be reconstructed from the time-trace + snapshot data, without the performance overhead of always-on logging.11

10 In the Linux source, see tools/perf/jvmti.

11 I have spoken about this to Stephane Eranian, who added the jvmti support to Linux perf(1),but I don’t think he or I have had the time to code it.

Making the stale symbols visible: It should be possible to dump a before and after symbol table, find locations that have changed, and then construct a new symbol table with these locations flagged as unreliable.

async-profile: This marries perf_events stack traces with those fetched using Java’s AsyncGetCallTrace interface. This approach does not require frame pointers to be enabled.

Kernel support: This has been discussed in the BPF community. One day we may add kernel support to improve such stack trace collection with in-kernel symbol translation. This was mentioned in Chapter 2.

JVM built-in support for symbol dumps: perf-map-agent is a single-threaded module that is bounded by the JVMTI interface. If the JVM were to support a way to write /tmp/perf-PID.map supplemental symbol files directly—say, when it received a signal or another JVMTI call—it is likely that such a built-in JVM version could be much more efficient.

This is an evolving space.

12.3.5 Java Stack Traces
By default, Java does not honor the frame pointer register, and that method of stack walking does not work. For example, using bpftrace to take timed stack samples of the Java process:

Click here to view code image


# bpftrace -e 'profile:hz:99 /pid == 3671/ { @[ustack] = count(); }'
Attaching 1 probe...
^C

@[
    0x7efcff88a7bd
    0x12f023020020fd4
]: 1
@[
    0x7efcff88a736
    0x12f023020020fd4
]: 1
@[
    IndexSet::alloc_block_containing(unsigned int)+75
    PhaseChaitin::interfere_with_live(unsigned int, IndexSet*)+628
    PhaseChaitin::build_ifg_physical(ResourceArea*)+1812
    PhaseChaitin::Register_Allocate()+1834
    Compile::Code_Gen()+628
    Compile::Compile(ciEnv*, C2Compiler*, ciMethod*, int, bool, bool, bool, Direct...
    C2Compiler::compile_method(ciEnv*, ciMethod*, int, DirectiveSet*)+177
    CompileBroker::invoke_compiler_on_method(CompileTask*)+931
    CompileBroker::compiler_thread_loop()+1224
    JavaThread::thread_main_inner()+259
    thread_native_entry(Thread*)+240
    start_thread+219
]: 1
@[
    0x7efcff72fc9e
    0x620000cc4
]: 1
@[
    0x7efcff969ba8
]: 1
[...]

This output includes broken stacks, seen as just one or two hex addresses. The Java compiler has used the frame pointer register for local variables, as a compiler optimization. This makes Java slightly faster (on register-limited processors), at the expense of breaking this method of stack walking as used by debuggers and tracers. Attempting to walk the stack trace usually either fails after the first address. The above output includes such failures, and also a working stack that is entirely C++: since the code path didn’t enter any Java methods, the frame pointer was intact.

PreserveFramePointer
Since Java 8 update 60, the JVM has provided the -XX:+PreserveFramePointer option to enable the frame pointer,12 which fixes frame pointer–based stack traces. Now the same bpftrace one-liner, but with Java running with this option (this involved adding the -XX:+PreserveFramePointer option to the start script, /usr/games/freecol, in the run_java line):

12 I developed this capability and sent it as a patch to the hotspot-compiler-devs mailing list, with a CPU flame graph to explain its value. Zoltán Majó from Oracle rewrote it to be parameterized (PreserveFramePointer) and integrated it in the official JDK.

Click here to view code image


# bpftrace -e 'profile:hz:99 /pid == 3671/ { @[ustack] = count(); }'
Attaching 1 probe...
^C
[...]
@[
    0x7fdbdf74ba04
    0x7fdbd8be8814
    0x7fdbd8bed0a4
    0x7fdbd8beb874
    0x7fdbd8ca336c
    0x7fdbdf96306c
    0x7fdbdf962504
    0x7fdbdf62fef8
    0x7fdbd8cd85b4
    0x7fdbd8c8e7c4
    0x7fdbdf9e9688
    0x7fdbd8c83114
    0x7fdbd8817184
    0x7fdbdf9e96b8
    0x7fdbd8ce57a4
    0x7fdbd8cbecac
    0x7fdbd8cb232c
    0x7fdbd8cc715c
    0x7fdbd8c846ec
    0x7fdbd8cbb154
    0x7fdbd8c7fdc4
    0x7fdbd7b25849
    JavaCalls::call_helper(JavaValue*, methodHandle const&, JavaCallArguments*, Th...
    JVM_DoPrivileged+1600
    0x7fdbdf77fe18
    0x7fdbd8ccd37c
    0x7fdbd8cd1674
    0x7fdbd8cd0c74
    0x7fdbd8c8783c
    0x7fdbd8bd8fac
    0x7fdbd8b8a7b4
    0x7fdbd8b8c514
]: 1
[...]

These stack traces are now complete, except for the symbol translation.

Stacks and Symbols
As covered in Section 12.3.4, a supplemental symbol file can be created with the perf-map-agent software, automated by jmaps. After taking this step in an END clause:

Click here to view code image


# bpftrace --unsafe -e 'profile:hz:99 /pid == 4663/ { @[ustack] = count(); }
    END { system("jmaps"); }'
Attaching 2 probes...
^CFetching maps for all java processes...
Mapping PID 4663 (user bgregg):
wc(1):   6555  20559 388964 /tmp/perf-4663.map
@[
    Lsun/awt/X11/XlibWrapper;::RootWindow+31
    Lsun/awt/X11/XDecoratedPeer;::getLocationOnScreen+3764
    Ljava/awt/Component;::getLocationOnScreen_NoTreeLock+2260
    Ljavax/swing/SwingUtilities;::convertPointFromScreen+1820
    Lnet/sf/freecol/client/gui/plaf/FreeColButtonUI;::paint+1068
    Ljavax/swing/plaf/ComponentUI;::update+1804
    Ljavax/swing/plaf/metal/MetalButtonUI;::update+4276
    Ljavax/swing/JComponent;::paintComponent+612
    Ljavax/swing/JComponent;::paint+2120
    Ljavax/swing/JComponent;::paintChildren+13924
    Ljavax/swing/JComponent;::paint+2168
    Ljavax/swing/JLayeredPane;::paint+2356
    Ljavax/swing/JComponent;::paintChildren+13924
    Ljavax/swing/JComponent;::paint+2168
    Ljavax/swing/JComponent;::paintToOffscreen+836
    Ljavax/swing/BufferStrategyPaintManager;::paint+3244
    Ljavax/swing/RepaintManager;::paint+1260
    Ljavax/swing/JComponent;::_paintImmediately+12636
    Ljavax/swing/JComponent;::paintImmediately+3564
    Ljavax/swing/RepaintManager$4;::run+1684
    Ljavax/swing/RepaintManager$4;::run+132
    call_stub+138
    JavaCalls::call_helper(JavaValue*, methodHandle const&, JavaCallArguments*, Th...
    JVM_DoPrivileged+1600
    Ljava/security/AccessController;::doPrivileged+216
    Ljavax/swing/RepaintManager;::paintDirtyRegions+4572
    Ljavax/swing/RepaintManager;::paintDirtyRegions+660
    Ljavax/swing/RepaintManager;::prePaintDirtyRegions+1556
    Ljavax/swing/RepaintManager$ProcessingRunnable;::run+572
    Ljava/awt/event/InvocationEvent;::dispatch+524
    Ljava/awt/EventQueue;::dispatchEventImpl+6260
    Ljava/awt/EventQueue$4;::run+372
]: 1

The stack is now complete, and fully translated. This stack looks like it was painting a button in the UI (FreeColButtonUI::paint()).

Library Stacks
One last example, this time tracing stack traces from the read(2) syscall:

Click here to view code image


# bpftrace -e 't:syscalls:sys_enter_read /pid == 4663/ { @[ustack] = count(); }'
Attaching 1 probe...
^C

@[
    read+68
    0xc528280f383da96d
]: 11
@[
    read+68
]: 25

These stacks are still broken, even though Java is running with -XX:+PreserveFramePointer. The problem is that this syscall has walked into the libc library’s read() function, and that library has not been compiled with the frame pointer. The fix is to recompile the library, or use a different stack walker once BPF tools support it (e.g., DWARF or LBR).

Fixing stack traces can be a lot of work. But it is worth it: it enables profiling including CPU flame graphs and stack trace context from any event.

12.3.6 Java USDT Probes
USDT probes, introduced in Chapter 2, have the advantage of providing a stable interface for instrumenting events. There are USDT probes in the JVM for various events, including:

Virtual machine life cycle

Thread life cycle

Class loading

Garbage collection

Method compilation

Monitor

Application tracking

Method calls

Object allocation

Monitor events

These are only available if the JDK has been compiled with the --enable-dtrace option, which, unfortunately, is not yet commonly enabled for Linux distributions of the JDK. To use these USDT probes, you will need to compile the JDK from source with --enable-dtrace, or ask the package maintainers to enable this option.

The probes are documented in the “DTrace Probes in HotSpot VM” section of the Java Virtual Machine Guide [138], which describes the purpose of each probe and its arguments. Table 12-3 lists some selected probes.

Table 12-3 USDT Probes

USDT Group

USDT Probe

Arguments

hotspot

thread__start, thread__stop

char *thread_name, u64 thread_name_len, u64 thread_id, u64 os_thread_id, bool is_daemon

hotspot

class__loaded

char *class_name, u64 class_name_len, u64 loader_id, bool is_shared

hotspot

gc__begin

bool is_full_gc

hotspot

gc__end

—

hotspot

object__alloc

int thread_id, char *class_name, u64 class_name_len, u64 size

hotspot

method__entry,

method__return

int thread_id, char *class_name, int class_name_len, char *method_name, int method_name_len, char *signature, int signature_len

hotspot_jni

AllocObject__entry

void *env, void *clazz

See the Java Virtual Machine Guide for the full list.

Java USDT Implementation
As an example of how the USDT probes have been inserted into the JDK, the following shows the code behind a hotspot:gc__begin probe. For most people, it is not necessary to learn these details; they have been provided just to give some insight into how the probes work.

The probe is defined in src/hotspot/os/posix/dtrace/hotspot.d, a definitions file for the USDT probes:


provider hotspot {
[...]
  probe gc__begin(uintptr_t);

From this definition, the probe will be called hotspot:gc__begin. At build time this file is compiled to a hotspot.h header file, containing a HOTSPOT_GC_BEGIN macro:

Click here to view code image


#define HOTSPOT_GC_BEGIN(arg1) \
DTRACE_PROBE1 (hotspot, gc__begin, arg1)

This macro is then inserted where needed in the JVM code. It has been put in a notify_gc_begin() function, so that that function can be called for executing the probe. From src/hotspot/share/gc/shared/gcVMOperations.cpp:

Click here to view code image


void VM_GC_Operation::notify_gc_begin(bool full) {
  HOTSPOT_GC_BEGIN(
                   full);
  HS_DTRACE_WORKAROUND_TAIL_CALL_BUG();
}

This function happens to have a DTrace bug workaround macro, which is declared in a dtrace.hpp header file with the comment “// Work around dtrace tail call bug 6672627 until it is fixed in solaris 10”.

If the JDK was built without --enable-dtrace, then a dtrace_disabled.hpp header file is used instead that returns nothing for these macros.

There is also a HOTSPOT_GC_BEGIN_ENABLED macro used for this probe: this returns true when the probe is under live instrumentation by a tracer, and is used by the code to know whether to calculate expensive probe arguments if the probe is enabled, or whether those can be skipped if no one is currently using the probe.

Listing Java USDT Probes
The tplist(8) tool from BCC can be used to list USDT probes from a file or a running process. On the JVM, it lists more than 500 probes. The output has been truncated here to show some interesting probes, and the full path to libjvm.so was elided (“...”):

Click here to view code image


# tplist -p 6820
/.../libjvm.so hotspot:class__loaded
/.../libjvm.so hotspot:class__unloaded
/.../libjvm.so hs_private:cms__initmark__begin
/.../libjvm.so hs_private:cms__initmark__end
/.../libjvm.so hs_private:cms__remark__begin
/.../libjvm.so hs_private:cms__remark__end
/.../libjvm.so hotspot:method__compile__begin
/.../libjvm.so hotspot:method__compile__end
/.../libjvm.so hotspot:gc__begin
/.../libjvm.so hotspot:gc__end
[...]
/.../libjvm.so hotspot_jni:NewObjectArray__entry
/.../libjvm.so hotspot_jni:NewObjectArray__return
/.../libjvm.so hotspot_jni:NewDirectByteBuffer__entry
/.../libjvm.so hotspot_jni:NewDirectByteBuffer__return
[...]
/.../libjvm.so hs_private:safepoint__begin
/.../libjvm.so hs_private:safepoint__end
/.../libjvm.so hotspot:object__alloc
/.../libjvm.so hotspot:method__entry
/.../libjvm.so hotspot:method__return
/.../libjvm.so hotspot:monitor__waited
/.../libjvm.so hotspot:monitor__wait
/.../libjvm.so hotspot:thread__stop
/.../libjvm.so hotspot:thread__start
/.../libjvm.so hotspot:vm__init__begin
/.../libjvm.so hotspot:vm__init__end
[...]

The probes are grouped into hotspot and hotspot_jni libraries. This output includes probes for class loading, garbage collection, safepoints, object allocation, methods, threads, and more. The use of double underscores was to create probe names that DTrace could refer to using a single dash, without the problem of putting minus signs in the code.

This example ran tplist(8) on a process; it can also be run on libjvm.so. So can readelf(1) to see the USDT probes in the ELF binary notes section (-n):

Click here to view code image


# readelf -n /.../jdk/lib/server/libjvm.so

Displaying notes found in: .note.gnu.build-id
  Owner                 Data size   Description
  GNU                  0x00000014   NT_GNU_BUILD_ID (unique build ID bitstring)
    Build ID: 264bc78da04c17524718c76066c6b535dcc380f2

Displaying notes found in: .note.stapsdt
  Owner                 Data size   Description
  stapsdt              0x00000050   NT_STAPSDT (SystemTap probe descriptors)
    Provider: hotspot
    Name: class__loaded
    Location: 0x00000000005d18a1, Base: 0x00000000010bdf68, Semaphore:
0x0000000000000000
    Arguments: 8@%rdx -4@%eax 8@152(%rdi) 1@%sil
  stapsdt              0x00000050   NT_STAPSDT (SystemTap probe descriptors)
    Provider: hotspot
    Name: class__unloaded
    Location: 0x00000000005d1cba, Base: 0x00000000010bdf68, Semaphore:
0x0000000000000000
    Arguments: 8@%rdx -4@%eax 8@152(%r12) 1@$0
[...]

Using Java USDT Probes
These probes can be used in both BCC and bpftrace. Their role and arguments are documented in the Java Virtual Machine Guide [138]. For example, using BCC trace(8) to instrument the gc-begin probe, and the first arguments which is a boolean to show whether this was a full garbage collection (1) or partial (0):

Click here to view code image


# trace -T -p $(pidof java) 'u:/.../libjvm.so:gc__begin "%d", arg1'
TIME     PID     TID     COMM            FUNC             -
09:30:34 11889   11900   VM Thread       gc__begin        0
09:30:34 11889   11900   VM Thread       gc__begin        0
09:30:34 11889   11900   VM Thread       gc__begin        0
09:30:38 11889   11900   VM Thread       gc__begin        1

This show partial GCs at 9:30:34 and a full GC at 9:30:38. Note that the JVM Guide documents this argument as args[0], however trace(8) numbers them beginning from 1, so it is arg1.

Here is an example with string arguments: the method__compile__begin probe has the compiler name, class name, and method name as the first, third, and fifth arguments. This shows the method name using trace(8):

Click here to view code image


# trace -p $(pidof java) 'u:/.../libjvm.so:method__compile__begin "%s", arg5'
PID     TID     COMM            FUNC             -
12600   12617   C1 CompilerThre method__compile__begin getLocationOnScreen
12600   12617   C1 CompilerThre method__compile__begin getAbsoluteX
12600   12617   C1 CompilerThre method__compile__begin getAbsoluteY
12600   12617   C1 CompilerThre method__compile__begin currentSegmentD
12600   12617   C1 CompilerThre method__compile__begin next
12600   12617   C1 CompilerThre method__compile__begin drawJoin
12600   12616   C2 CompilerThre method__compile__begin needsSyncData
12600   12617   C1 CompilerThre method__compile__begin getMouseInfoPeer
12600   12617   C1 CompilerThre method__compile__begin fillPointWithCoords
12600   12616   C2 CompilerThre method__compile__begin isHeldExclusively
12600   12617   C1 CompilerThre method__compile__begin updateChildGraphicsData
Traceback (most recent call last):
  File "_ctypes/callbacks.c", line 315, in 'calling callback function'
  File "/usr/local/lib/python2.7/dist-packages/bcc/table", line 572, in raw_cb_
    callback(cpu, data, size)
  File "/home/bgregg/Build/bcc/tools/trace", line 567, in print_event
    self._display_function(), msg))
UnicodeDecodeError: 'ascii' codec can't decode byte 0xff in position 10: ordinal not
in range(128)
12600   12616   C2 CompilerThre method__compile__begin getShowingSubPanel%
[...]

The first 11 lines show the method name as the last column, followed by a Python error about decoding a byte as ASCII. The problem is explained in the Java Virtual Machine Guide for these probes: the strings are not NULL terminated, and separate lengths are provided as additional arguments. To avoid errors like this, your BPF program needs to use the string length from the probe.

Switching to bpftrace, which can use the length argument in its str() built-in:

Click here to view code image


# bpftrace -p $(pgrep -n java) -e 'U:/.../libjvm.so:method__compile__begin
{ printf("compiling: %s\n", str(arg4, arg5)); }'
Attaching 1 probe...
compiling: getDisplayedMnemonicIndex
compiling: getMinimumSize
compiling: getBaseline
compiling: fillParallelogram
compiling: preConcatenate
compiling: last
compiling: nextTile
compiling: next
[...]

There are no more errors in the output, which is now printing the strings with their correct lengths. Any BCC or bpftrace program that uses these probes needs to use the length argument in this way.

As another example that leads to the next section, the following frequency counts all USDT probes beginning with “method”:

Click here to view code image


# funccount -p $(pidof java) 'u:/.../libjvm.so:method*'
Tracing 4 functions for "u:/.../libjvm.so:method*"... Hit Ctrl-C to end.
^C
FUNC                                    COUNT
method__compile__begin                   2056
method__compile__end                     2056
Detaching...

While tracing, the method_compile__begin and method__compile__end probes fired 2056 times. However, the method__entry and method__return probes were not traced. The reason is that they are part of the extended USDT probe set, covered next.

Extended Java USDT Probes
Some JVM USDT probes are not used by default: method entry and return, object-alloc, and Java monitor probes. This is because they are very high-frequency events, and their not-enabled overhead incurs a high performance penalty—likely exceeding 10%. This is just the overhead of making them available, and when they are not in use! When they are enabled and used, the overhead will slow down Java much more, possibly making Java run 10 times slower (10x) or more.

So that Java users do not pay a penalty for something they never use, these probes are not available unless Java is run with an option: -XX:+ExtendedDTraceProbes.

The following shows the Java game freecol with ExtendedDTraceProbes enabled, and frequency counting USDT probes beginning with “method” as before:

Click here to view code image


# funccount -p $(pidof java) 'u:/.../libjvm.so:method*'
Tracing 4 functions for "u:/.../libjvm.so:method*"... Hit Ctrl-C to end.
^C
FUNC                                    COUNT
method__compile__begin                    357
method__compile__end                      357
method__return                       26762077
method__entry                        26762245
Detaching...

While tracing, there were 26 million calls to method__entry and method__return. The game also suffered extreme lag, taking around three seconds for any input to be processed. As a measure of before and after, the freecol start to splash screen time was 2 seconds by default, and 22 seconds when instrumenting these method probes: a slowdown of over 10x.

These high-frequency probes may be more useful for troubleshooting software issues in a lab environment than for the analysis of production workloads.

The sections that follow show different BPF tools for Java observability, now that I have covered the necessary background: libjvm, Java symbols, Java stack traces, and Java USDT probes.

12.3.7 profile
The BCC profile(8) tool was covered in Chapter 6. There are many profilers for Java. The advantage of BCC profile(8) is that it is efficient, frequency counting stacks in kernel context, and complete, showing user- and kernel-mode CPU consumers. Time spent in native libraries (e.g., libc), libjvm, Java methods, and the kernel can all be seen via profile(8).

Java Prerequisites
For profile(8) to see the full stack, Java must be running with -XX:+PreserveFramePointer, and a supplemental symbol file must be created using perf-map-agent, which profile(8) will make use of (see Section 12.3.4). To translate frames in libjvm.so, symbol tables are needed. These requirements were discussed in earlier sections.

CPU Flame Graph
This is an example of using profile(8) with Java to generate a mixed-mode CPU flame graph.

This Java program, freecol, is running with -XX:+PreserveFramePointer, and with an ELF symbol table for its libjvm functions. The jmaps utility, introduced earlier, is run immediately before the profile(8) tool to minimize symbol churn. This profiles at the default rate (99 Hertz), with kernel annotations on symbol names (-a), folded format for flame graphs (-f), for PID 16914 (-p) and for 10 seconds:

Click here to view code image


# jmaps; profile -afp 16914 10 > out.profile01.txt
Fetching maps for all java processes...
Mapping PID 16914 (user bgregg):
wc(1):   9078  28222 572219 /tmp/perf-16914.map
# wc out.profile01.txt
   215   3347 153742 out.profile01.txt
# cat out.profile01.txt
AWT-EventQueue-;start_thread;thread_native_entry(Thread*);Thread::call... 1
[...]

The wc(1) utility is used by jmaps to show the size of the symbol file, which is 9078 lines long, and therefore contains 9078 symbols. I’ve also used wc(1) to show the size of the profile file. The output of profile(8) in folded mode is one line per stack, semicolon-delimited frames, and a count for the number of times the stack was seen. wc(1) reported 215 lines in the profile output, so there were 215 unique stack traces collected.

This profile output can be converted into a flame graph using my open source FlameGraph software [37] and the command:

Click here to view code image

flamegraph.pl --color=java --hash < out.profile01.txt > out.profile02.svg
The --color=java option uses a palette that colors code types with different hues: java is green, C++ is yellow, user-level native is red, and kernel-level native is orange. The --hash option uses consistent coloring based on the function names rather than random saturation levels.

The resulting flame graph SVG file can be opened in a web browser. Figure 12-2 shows a screenshot.


Figure 12-2 CPU flame graph

A mouse-over of each frame provides additional details, such as the percentage it was present in the profile. These showed that 55% of CPU time was in the C2 compiler, shown by the large wide tower (vertical column of rectangles) in the middle of C++ frames. Only 29% of time was spent in the Java freecol game, shown by the towers containing Java frames.

By clicking on the Java tower on the left, the Java frames can be zoomed in, as shown in Figure 12-3.


Figure 12-3 CPU flame graph zoomed

Now details of the Java freecol game and its methods can be read. Most of this time is in paint methods, and where exactly the CPU cycles were spent can be seen as the top edge in the flame graph.

If you were interested in improving the performance of freecol, this CPU flame graph has already provided two targets from an initial glance. You could look through the JVM tunables to see what options would cause the C2 compiler to consume less CPU time.13 The paint methods can also be inspected in detail, with the freecol source, to look for more efficient techniques.

13 Compiler tunables include -XX:CompileThreshold, -XX:MaxInlineSize, -XX:InlineSmallCode, and -XX:FreqInlineSize. Using -Xcomp to pre-compile methods may also be an illustrative experiment.

For long profiles (say, over two minutes), the time between the symbol table dump and when stack traces are collected can be so large that the C2 compiler has moved some methods in the meantime, so the symbol table is no longer accurate. This may be noticed by a code path that makes no sense at all, since some frames are mistranslated. A much more common issue with unexpected code paths is inlining.

Inlining
Since this is visualizing the stack trace that is running on-CPU, it is showing Java methods after inlining. JVM inlining can be aggressive, inlining as much as two frames out of every three. This can make browsing the flame graph a little confusing, as methods appear to be directly calling other methods that they do not in the source code.

There is a solution to inlining: the perf-map-agent software supports dumping a symbol table that includes all inlined symbols. jmaps will use this capability with -u:

Click here to view code image


# jmaps -u; profile -afp 16914 10 > out.profile03.txt
Fetching maps for all java processes...
Mapping PID 16914 (user bgregg):
wc(1):    75467   227393 11443144 /tmp/perf-16914.map

The number of symbols has greatly increased, from the 9078 seen earlier to over 75,000. (I ran jmaps again, with -u, and it was still around 9000.)

Figure 12-4 shows a flame graph generated with the uninlined frame information.


Figure 12-4 CPU flame graph with uninlining

The tower in the freecol stack is now much higher, as it includes uninlined frames (colored aqua).

Including inlined frames slows down the jmaps step as it must dump many more symbols, as well as the flame graph generation to parse and include them. In practice, this is sometimes necessary. Often, a flame graph without inlined frames is sufficient to solve issues because it still shows the overall code flow, while bearing in mind that some methods are not visible.

bpftrace
The profile(8) functionality can also be implemented in bpftrace, which has an advantage: the jmaps tool can be run in an END clause using the system() function. For example, the following one-liner was shown in an earlier section:

Click here to view code image

bpftrace --unsafe -e 'profile:hz:99 /pid == 4663/ { @[ustack] = count(); } END
 { system("jmaps"); }'
This samples user-level stack traces for PID 4663 at 99 Hertz across all CPUs that PID is running on. It can be adjusted to include the kernel stack and the process name by making the map @[kstack, ustack, comm].

12.3.8 offcputime
The BCC offcputime(8) tool was covered in Chapter 6. It collects stacks on CPU blocking events (scheduler context switches), and sums the time spent blocked by stack trace. For offcputime(8) to work with Java, see Section 12.3.7.

For example, using offcputime(8) on the Java freecol game:

Click here to view code image


# jmaps; offcputime -p 16914 10
Fetching maps for all java processes...
Mapping PID 16914 (user bgregg):
wc(1):   9863  30589 623898 /tmp/perf-16914.map

Tracing off-CPU time (us) of PID 16914 by user + kernel stack for 10 secs.
^C

[...]

    finish_task_switch
    schedule
    futex_wait_queue_me
    futex_wait
    do_futex
    SyS_futex
    do_syscall_64
    entry_SYSCALL_64_after_hwframe
    __lll_lock_wait
    SafepointSynchronize::block(JavaThread*, bool)

    SafepointMechanism::block_if_requested_slow(JavaThread*)
    JavaThread::check_safepoint_and_suspend_for_native_trans(JavaThread*)
    JavaThread::check_special_condition_for_native_trans(JavaThread*)
    Lsun/awt/X11/XlibWrapper;::XEventsQueued
    Lsun/awt/X11/XToolkit;::run
    Interpreter
    Interpreter
    call_stub
    JavaCalls::call_helper(JavaValue*, methodHandle const&, JavaCallArguments*, Th...
    JavaCalls::call_virtual(JavaValue*, Handle, Klass*, Symbol*, Symbol*, Thread*)
    thread_entry(JavaThread*, Thread*)
    JavaThread::thread_main_inner()
    Thread::call_run()
    thread_native_entry(Thread*)
    start_thread
    -                AWT-XAWT (16944)
        5171

[...]

    finish_task_switch
    schedule
    io_schedule
    bit_wait_io
    __wait_on_bit
    out_of_line_wait_on_bit
    __wait_on_buffer
    ext4_find_entry
    ext4_unlink
    vfs_unlink
    do_unlinkat
    sys_unlink
    do_syscall_64
    entry_SYSCALL_64_after_hwframe
    __GI_unlink
    Ljava/io/UnixFileSystem;::delete0
    Ljava/io/File;::delete
    Interpreter
    Interpreter
    Interpreter
    Lnet/sf/freecol/client/control/InGameInputHandler;::handle
    Interpreter
    Lnet/sf/freecol/client/control/InGameInputHandler;::handle
    Lnet/sf/freecol/common/networking/Connection;::handle
    Interpreter
    call_stub
    JavaCalls::call_helper(JavaValue*, methodHandle const&, JavaCallArguments*, Th...
    JavaCalls::call_virtual(JavaValue*, Handle, Klass*, Symbol*, Symbol*, Thread*)
    thread_entry(JavaThread*, Thread*)
    JavaThread::thread_main_inner()
    Thread::call_run()
    thread_native_entry(Thread*)
    start_thread
    -                FreeColClient:b (8168)
        7679

[...]

    finish_task_switch
    schedule
    futex_wait_queue_me
    futex_wait
    do_futex
    SyS_futex
    do_syscall_64
    entry_SYSCALL_64_after_hwframe
    pthread_cond_timedwait@@GLIBC_2.3.2
    __pthread_cond_timedwait
    os::PlatformEvent::park(long) [clone .part.12]
    Monitor::IWait(Thread*, long)
    Monitor::wait(bool, long, bool)
    WatcherThread::sleep() const
    WatcherThread::run()
    thread_native_entry(Thread*)
    start_thread
    __clone
    -                VM Periodic Tas (22029)
        9970501

The output has been truncated as it was many pages long. A few interesting stacks have been included here to discuss.

The first shows Java blocking for 5.1 milliseconds (5717 us) in total on a safepoint, which was handled using a futex lock in the kernel. These times are totals, so this 5.1 ms may include multiple blocking events.

The last stack shows Java blocking in pthread_cond_timedwait() for almost the same 10-second duration of the trace: it is a WatcherThread waiting for work, with the thread name “VM Periodic Tas” (truncated to appear without the “k”). For some application types that use many threads that wait for work, the output of offcputime(8) can be dominated by these waiting stacks, and you need to read past them to find the stacks that matter: the wait events during application requests.

The second stack surprised me: it shows Java blocked on an unlink(2) syscall, to delete a file, which ended up blocking on disk I/O (io_schedule() etc). What files is freecol deleting during gameplay? A bpftrace one-liner to show unlink(2) with the pathname deleted reveals:

Click here to view code image


# bpftrace -e 't:syscalls:sys_enter_unlink /pid == 16914/ { printf("%s\n",
    str(args->pathname)); }'
Attaching 1 probe...
/home/bgregg/.local/share/freecol/save/autosave/Autosave-before
/home/bgregg/.local/share/freecol/save/autosave/Autosave-before
[...]

freecol is deleting auto savegames.

libpthread Stacks
Since this may be a commonly seen issue, here is how the final stack looked with a default install of libpthread:

Click here to view code image


    finish_task_switch
    schedule
    futex_wait_queue_me
    futex_wait
    do_futex
    SyS_futex
    do_syscall_64
    entry_SYSCALL_64_after_hwframe
    pthread_cond_timedwait
    -                VM Periodic Tas (16936)
        9934452

The stack ends at pthread_cond_timedwait(). The current default libpthread that is shipped with many Linux distributions has been compiled with -fomit-frame-pointer, a compiler optimization that breaks frame pointer–based stack walking. My earlier example used my own compiled version of libpthread with -fno-omit-frame-pointer. See Section 2.4 in Chapter 2 for more about this.

Off-CPU Time Flame Graphs
The output of offcputime(8) was hundreds of pages long. To navigate it more quickly, it can be used to generate off-CPU time flame graphs. Here is an example using the FlameGraph software [37]:

Click here to view code image


# jmaps; offcputime -fp 16914 10 > out.offcpu01.txt
Fetching maps for all java processes...
Mapping PID 16914 (user bgregg):
wc(1):  12015  37080 768710 /tmp/perf-16914.map
# flamegraph.pl --color=java --bgcolor=blue --hash --countname=us --width=800 \
    --title="Off-CPU Time Flame Graph" < out.offcpu01.txt > out.offcpu01.svg

This generated the graph shown in Figure 12-5.


Figure 12-5 Off-CPU time flame graph

The top of this flame graph has been truncated. The width of each frame is relative to the blocked off-CPU time. Since offcputime(8) is showing stack traces with their total blocking time in microseconds, the --countname=us option to flamegraph.pl is used to match this, which changes the information shown for mouse-overs. The background color was also changed to blue, as a visual reminder that this is showing blocking stacks. (CPU flame graphs use a yellow background.)

This flame graph is dominated by threads waiting for events. Since the thread name is included as the first frame in the stack, it groups threads with the same name together as a tower. Each tower in this flame graph shows waiting threads.

But I am not interested in threads waiting for events: I am interested in threads waiting during an application request. This application was freecol, and using the flame graph search feature for “freecol” highlighted those frames in magenta (see Figure 12-6).


Figure 12-6 Off-CPU time flame graph, searching for application code

Using click-to-zoom on the narrow third tower showed code during the game (see Figure 12-7).


Figure 12-7 Off-CPU time flame graph zoomed

The graph shown in Figure 12-7 shows the blocking paths in freecol, providing targets to begin optimizing. Many of these frames were still “Interpreter”, as the JVM had not executed that method enough times to hit the CompileThreshold.

Sometimes the application code paths can be so narrow due to other waiting threads that they are elided from the flame graph. One approach to solve this is to use grep(1) at the command line to include only the stacks of interest. For example, matching those containing the application name “freecol”:

Click here to view code image

# grep freecol out.offcpu01.txt | flamegraph.pl ... > out.offcpu01.svg
It is one of the benefits of the folded-file format for stack traces: it can be easily manipulated as needed before generation as a flame graph.

12.3.9 stackcount
The BCC stackcount(8) tool, covered in Chapter 4, can collect stacks on any event, which can show the libjvm and Java method code paths that led to the event. For stackcount(8) to work with Java, see Section 12.3.7.

For example, using stackcount(8) to show user-level page faults, which is a measure of main memory growth:

Click here to view code image


# stackcount -p 16914 t:exceptions:page_fault_user
Tracing 1 functions for "t:exceptions:page_fault_user"... Hit Ctrl-C to end.
^C

[...]

  do_page_fault
  page_fault
  Interpreter
  Lnet/sf/freecol/server/control/ChangeSet$MoveChange;::consequences
  [unknown]
  [unknown]
  Lnet/sf/freecol/server/control/InGameController;::move
  Lnet/sf/freecol/common/networking/MoveMessage;::handle
  Lnet/sf/freecol/server/control/InGameInputHandler$37;::handle
  Lnet/sf/freecol/common/networking/CurrentPlayerNetworkRequestHandler;::handle
  [unknown]
  Lnet/sf/freecol/server/ai/AIMessage;::ask
  Lnet/sf/freecol/server/ai/AIMessage;::askHandling
  Lnet/sf/freecol/server/ai/AIUnit;::move
  Lnet/sf/freecol/server/ai/mission/Mission;::moveRandomly
  Lnet/sf/freecol/server/ai/mission/UnitWanderHostileMission;::doMission
  Ljava/awt/Container;::isParentOf
  [unknown]
  Lcom/sun/org/apache/xerces/internal/impl/XMLEntityScanner;::reset
  call_stub
  JavaCalls::call_helper(JavaValue*, methodHandle const&, JavaCallArguments*, Thre...
  JavaCalls::call_virtual(JavaValue*, Handle, Klass*, Symbol*, Symbol*, Thread*)
  thread_entry(JavaThread*, Thread*)
  JavaThread::thread_main_inner()
  Thread::call_run()
  thread_native_entry(Thread*)
  start_thread
    4

[...]

  do_page_fault
  page_fault
  __memset_avx2_erms
  PhaseChaitin::Register_Allocate()
  Compile::Code_Gen()
  Compile::Compile(ciEnv*, C2Compiler*, ciMethod*, int, bool, bool, bool, Directiv...
  C2Compiler::compile_method(ciEnv*, ciMethod*, int, DirectiveSet*)
  CompileBroker::invoke_compiler_on_method(CompileTask*)
  CompileBroker::compiler_thread_loop()
  JavaThread::thread_main_inner()
  Thread::call_run()
  thread_native_entry(Thread*)
  start_thread
    414

Although many stacks were shown, only two have been included here. The first shows a page fault through freecol ai code; the second is from the JVM C2 compiler generating code.

Page Fault Flame Graph
A flame graph can be generated from the stack count output to aid browsing. For example, using the FlameGraph software [37]:

Click here to view code image


# jmaps; stackcount -p 16914 t:exceptions:page_fault_user > out.faults01.txt
Fetching maps for all java processes...
Mapping PID 16914 (user bgregg):
wc(1):  12015  37080 768710 /tmp/perf-16914.map
# stackcollapse.pl < out.faults01.txt | flamegraph.pl --width=800 \
    --color=java --bgcolor=green --title="Page Fault Flame Graph" \
    --countname=pages > out.faults01.svg

This generated the truncated graph shown in Figure 12-8.


Figure 12-8 Page fault flame graph

A green background color was used as a visual reminder that this is a memory-related flame graph. In this screenshot I have zoomed to inspect the freecol code paths. This provides one view of memory growth by the application, and each path can be quantified (by its width) and studied from the flame graph.

bpftrace
The stackcount(8) functionality can be implemented as a bpftrace one-liner, for example:

Click here to view code image


# bpftrace --unsafe -e 't:exceptions:page_fault_user /pid == 16914/ {
    @[kstack, ustack, comm] = count(); } END { system("jmaps"); }'
Attaching 1 probe...
^C
[...]

@[
    do_page_fault+204
    page_fault+69
,
    0x7fa369bbef2d
    PhaseChaitin::Register_Allocate()+930
    Compile::Code_Gen()+650
    Compile::Compile(ciEnv*, C2Compiler*, ciMethod*, int, bool, bool, bool, Direct...
    C2Compiler::compile_method(ciEnv*, ciMethod*, int, DirectiveSet*)+188
    CompileBroker::invoke_compiler_on_method(CompileTask*)+1016
    CompileBroker::compiler_thread_loop()+1352
    JavaThread::thread_main_inner()+446
    Thread::call_run()+376
    thread_native_entry(Thread*)+238
    start_thread+219
, C2 CompilerThre]: 3

[...]

The execution of the jmaps for Java method symbols has been moved to the END clause, so it is run immediately before the stacks are printed out.

12.3.10 javastat
javastat(8)14 is a BCC tool that provides high-level Java and JVM statistics. It refreshes the screen similarly to top(1), unless the -C option is used. For example, running javastat(8) for the Java freecol game:

14 Origin: This was created by Sasha Goldshtein as a wrapper to his ustat(8) tool from 26-Oct-2016. I created a similar tool for DTrace called j_stat.d on 9-Sep-2007 to demonstrate these new probes in the DTraceToolkit.

Click here to view code image


# javastat -C
Tracing... Output every 1 secs. Hit Ctrl-C to end

14:16:56 loadavg: 0.57 3.66 3.93 2/3152 32738

PID    CMDLINE              METHOD/s   GC/s   OBJNEW/s   CLOAD/s  EXC/s  THR/s
32447  /home/bgregg/Build/o 0          0      0          0        169    0

14:16:58 loadavg: 0.57 3.66 3.93 8/3157 32744

PID    CMDLINE              METHOD/s   GC/s   OBJNEW/s   CLOAD/s  EXC/s  THR/s
32447  /home/bgregg/Build/o 0          1      0          730      522    6

14:16:59 loadavg: 0.69 3.64 3.92 2/3155 32747

PID    CMDLINE              METHOD/s   GC/s   OBJNEW/s   CLOAD/s  EXC/s  THR/s
32447  /home/bgregg/Build/o 0          2      0          8        484    1
[...]

The columns show:

PID: Process ID.

CMDLINE: Process command line. This example has truncated the path to my custom JDK build.

METHOD/s: Method calls per second.

GC/s: Garbage collection events per second.

OBJNEW/s: New objects per second.

CLOAD/s: Class loads per second.

EXC/s: Exceptions per second.

THR/s: Threads created per second.

This works by using Java USDT probes. The METHOD/s and OBJNEW/s columns will be zero unless the -XX:+ExtendedDTraceProbes option is used, which activates those probes, however, with a high overhead cost. As described earlier, an application may run 10 times slower with these probes enabled and instrumented.

Command line usage:

Click here to view code image

javastat [options] [interval [count]]
Options include:

-C: Don’t clear the screen

javastat(8) is really a wrapper to a ustat(8) tool in BCC’s tools/lib directory, which handles multiple languages.

12.3.11 javathreads
javathreads(8)15 is a bpftrace tool to show thread start and stop events. Example output for when freecol was started:

15 Origin: I created this for this book on 19-Feb-2019.

Click here to view code image


# javathreads.bt
Attaching 3 probes...
TIME                     PID/TID   -- THREAD
14:15:00   3892/3904  => Reference Handler
14:15:00   3892/3905  => Finalizer
14:15:00   3892/3906  => Signal Dispatcher
14:15:00   3892/3907  => C2 CompilerThread0
14:15:00   3892/3908  => C1 CompilerThread0
14:15:00   3892/3909  => Sweeper thread
14:15:00   3892/3910  => Common-Cleaner
14:15:01   3892/3911  => C2 CompilerThread1
14:15:01   3892/3912  => Service Thread
14:15:01   3892/3911  <= C2 CompilerThread1
14:15:01   3892/3917  => Java2D Disposer
14:15:01   3892/3918  => AWT-XAWT
14:15:02   3892/3925  => AWT-Shutdown
14:15:02   3892/3926  => AWT-EventQueue-0
14:15:02   3892/3934  => C2 CompilerThread1
14:15:02   3892/3935  => FreeColClient:-Resource loader
14:15:02   3892/3937  => FreeColClient:Worker
14:15:02   3892/3935  <= FreeColClient:-Resource loader
14:15:02   3892/3938  => FreeColClient:-Resource loader
14:15:02   3892/3939  => Image Fetcher 0
14:15:03   3892/3952  => FreeColClient:-Resource loader
[...]

This shows the creation and execution of threads and also some that were short-lived and finished during tracing (“<=”).

This tool uses the Java USDT probes. Since the rate of thread creation is low, the overhead of this tool should be negligible. Source code:

Click here to view code image


#!/usr/local/bin/bpftrace

BEGIN
{
        printf("%-20s  %6s/%-5s -- %s\n", "TIME", "PID", "TID", "THREAD");
}

usdt:/.../libjvm.so:hotspot:thread__start
{
        time("%H:%M:%S ");
        printf("%6d/%-5d => %s\n", pid, tid, str(arg0, arg1));
}

usdt:/.../libjvm.so:hotspot:thread__stop
{
        time("%H:%M:%S ");
        printf("%6d/%-5d <= %s\n", pid, tid, str(arg0, arg1));
}

The path to the library has been truncated in this source (“...”) but needs to be replaced with your libjvm.so library path. In the future bpftrace should also support specifying the library name without the path, so that this can simply be written as “libjvm.so”.

12.3.12 javacalls
javacalls(8)16 is a BCC and bpftrace tool that counts Java method calls. For example:

16 Origin: this was created by Sasha Goldshtein as a wrapper to his ucalls(8) tool from 19-Oct-2016, and I wrote the bpftrace version for this book on 11-Mar-2019. I created a similar tool for DTrace called j_calls.d on 9-Sep-2007.

Click here to view code image


# javacalls 16914
Tracing calls in process 16914 (language: java)... Ctrl-C to quit.
If you do not see any results, make sure you ran java with option -XX:
+ExtendedDTraceProbes
^C
METHOD                                              # CALLS
net/sf/freecol/client/control/InGameInputHandler$$Lambda$443.get$Lambda        1
sun/awt/X11/XWindowPeer.getLocalHostname                  1
net/sf/freecol/common/model/UnitType.getSpace             1
[...]
java/awt/image/Raster.getHeight                      129668
java/lang/Math.min                                   177085
jdk/internal/misc/Unsafe.getByte                     201047
java/lang/AbstractStringBuilder.putStringAt          252367
java/lang/AbstractStringBuilder.getCoder             252367
java/lang/String.getBytes                            253184
java/lang/AbstractStringBuilder.append               258491
java/lang/Object.<init>                              258601
java/lang/AbstractStringBuilder.ensureCapacityInternal   258611
java/lang/String.isLatin1                            265540
java/lang/StringBuilder.append                       286637
jdk/internal/misc/Unsafe.putInt                      361628
java/lang/System.arraycopy                           399118
java/lang/String.length                              427242
jdk/internal/misc/Unsafe.getInt                      700137
java/lang/String.coder                              1268791

The most frequent method while tracing was java/lang/String.code(), which was called 1,268,791 times.

This works by using Java USDT probes with -XX:+ExtendedDTraceProbes, which comes with a high performance cost. As described earlier, an application may run 10 times slower with this enabled and instrumented.

BCC
Command line usage:

Click here to view code image

javacalls [options] pid [interval]
Options include:

-L: Show method latency instead of call counts

-m: Report method latency as milliseconds

javacalls(8) is really a wrapper to a ucalls(8) tool in BCC’s tools/lib directory, which handles multiple languages.

bpftrace
Here is the source for the bpftrace version:

Click here to view code image


#!/usr/local/bin/bpftrace

BEGIN
{
        printf("Tracing Java method calls. Ctrl-C to end.\n");
}

usdt:/.../libjvm.so:hotspot:method__entry
{
        @[str(arg1, arg2), str(arg3, arg4)] = count();
}

The key to the map is two strings: the class and then the method name. As with the BCC version, this tool will only work with -XX:+ExtendedDTraceProbes, and an expected high performance cost. Also note that the full path to libjvm.so has been truncated, and will need to be replaced by your libjvm.so path.

12.3.13 javaflow
javaflow(8)17 is a BCC tool that shows the flow of Java method calls. For example:

17 Origin: This was created by Sasha Goldshtein as a wrapper to his uflow(8) tool from 27-Oct-2016. I created a similar tool for DTrace called j_flowtime.d on 9-Sep-2007.

Click here to view code image


# javaflow 16914
Tracing method calls in java process 16914... Ctrl-C to quit.
CPU PID  TID  TIME(us) METHOD
5   622  652  0.135    -> sun/awt/SunToolkit-.awtUnlock
5   622  652  0.135      -> java/util/concurrent/locks/ReentrantLock.unlock
5   622  652  0.135        -> java/util/concurrent/locks/AbstractQueuedSynchronize...
5   622  652  0.135          -> java/util/concurrent/locks/ReentrantLock$Sync.tryR...
5   622  652  0.135            -> java/util/concurrent/locks/AbstractQueuedSynchro...
5   622  652  0.135            <- java/util/concurrent/locks/AbstractQueuedSynchro...
5   622  652  0.135            -> java/lang/Thread.currentThread
5   622  652  0.135            <- java/lang/Thread.currentThread
5   622  652  0.135            -> java/util/concurrent/locks/AbstractOwnableSynchr...
5   622  652  0.135            <- java/util/concurrent/locks/AbstractOwnableSynchr...
5   622  652  0.135            -> java/util/concurrent/locks/AbstractQueuedSynchro...
5   622  652  0.135            <- java/util/concurrent/locks/AbstractQueuedSynchro...
5   622  652  0.135          <- java/util/concurrent/locks/ReentrantLock$Sync.tryR...
5   622  652  0.135        <- java/util/concurrent/locks/AbstractQueuedSynchronize...
5   622  652  0.135      <- java/util/concurrent/locks/ReentrantLock.unlock
5   622  652  0.135    <- sun/awt/SunToolkit-.awtUnlock
5   622  652  0.135  <- sun/awt/X11/XToolkit.getNextTaskTime
5   622  652  0.135  -> sun/awt/X11/XToolkit.waitForEvents
5   622  652  0.135    -> sun/awt/SunToolkit-.awtUnlock
[...]
1   622  654  4.159                              <- sun/java2d/SunGraphics2D.drawI...
Possibly lost 9 samples
1   622  654  4.159                              <- net/sf/freecol/common/model/Ti...
Possibly lost 9 samples
1   622  654  4.159                                  <- java/util/AbstractList.<init>
[...]

This shows the code flow: which method calls which other method and so on. Each child method call increases the indentation in the METHOD column.

This works by using Java USDT probes with -XX:+ExtendedDTraceProbes, which comes with a high performance cost. As described earlier, an application may run 10 times slower with this enabled and instrumented. This example also shows “Possibly lost 9 samples” messages: BPF tooling cannot keep up with the events, and as a safety valve is letting events be missed rather than blocking the application, while informing the user that this happened.

Command line usage:

javaflow [options] pid
Options include:

-M METHOD: Only trace calls to methods with this prefix

javaflow(8) is really a wrapper to a uflow(8) tool in BCC’s tools/lib directory, which handles multiple languages.

12.3.14 javagc
javagc(8)18 is a BCC tool that shows JVM garbage collection events. For example:

18 Origin: This was created by Sasha Goldshtein as a wrapper to his ugc(8) tool from 19-Oct-2016.

Click here to view code image


# javagc 16914
Tracing garbage collections in java process 16914... Ctrl-C to quit.
START    TIME(us) DESCRIPTION
5.586    1330.00  None
5.586    1339.00  None
5.586    1340.00  None
5.586    1342.00  None
5.586    1344.00  None
[...]

This shows when the GC event occurred as an offset from when javagc(8) began running (the START column, which is in seconds), and then the duration of the GC event (TIME column, in microseconds).

This works by using the standard Java USDT probes.

Command line usage:

javagc [options] pid
Options include:

-m: Report times in milliseconds

javagc(8) is really a wrapper to a ugc(8) tool in BCC’s tools/lib directory, which handles multiple languages.

12.3.15 javaobjnew
javaobjnew(8)19 is a BCC tool that counts Java object allocations. For example, running it with -C 10 to show the top 10 allocations by count:

19 Origin: This was created by Sasha Goldshtein as a wrapper to his uobjnew(8) tool from 25-Oct-2016. I created a similar tool for DTrace called j_objnew.d on 9-Sep-2007.

Click here to view code image


# javaobjnew 25102
Tracing allocations in process 25102 (language: java)... Ctrl-C to quit.
^C
NAME/TYPE                      # ALLOCS      # BYTES
java/util/ArrayList              429837            0
[Ljava/lang/Object;              434980            0
java/util/ArrayList$Itr          458430            0
java/util/HashMap$KeySet         545194            0
[B                               550624            0
java/util/HashMap$Node           572089            0
net/sf/freecol/common/model/Map$Position   663721            0
java/util/HashSet                696829            0
java/util/HashMap                714633            0
java/util/HashMap$KeyIterator    904244            0

The most frequent new object while tracing was java/util/HashMap$KeyIterator, which was created 904,244 times. The BYTES column is zero as it is not supported for this language type.

This works by using Java USDT probes with -XX:+ExtendedDTraceProbes, which comes with a high performance cost. As described earlier, an application may run 10 times slower with this enabled and instrumented.

Command line usage:

Click here to view code image

javaobjnew [options] pid [interval]
Options include:

-C TOP_COUNT: Show this many objects by count

-S TOP_SIZE: Show this many objects by size

javaobjnew(8) is really a wrapper to a uobjnew(8) tool in BCC’s tools/lib directory, which handles multiple languages (some of which do support the BYTES column).

12.3.16 Java One-Liners
These sections show BCC and bpftrace one-liners. Where possible, the same one-liner is implemented using both BCC and bpftrace.

BCC
Count JNI events beginning with “jni_Call”:

Click here to view code image

funccount '/.../libjvm.so:jni_Call*'
Count Java method events:

Click here to view code image

funccount -p $(pidof java) 'u:/.../libjvm.so:method*'
Profile Java stack traces and thread names at 49 Hertz:

Click here to view code image

profile -p $(pidof java) -UF 49
bpftrace
Count JNI events beginning with “jni_Call”:

Click here to view code image

bpftrace -e 'u:/.../libjvm.so:jni_Call* { @[probe] = count(); }'
Count Java method events:

Click here to view code image

bpftrace -e 'usdt:/.../libjvm.so:method* { @[probe] = count(); }'
Profile Java stack traces and thread names at 49 Hertz:

Click here to view code image

bpftrace -e 'profile:hz:49 /execname == "java"/ { @[ustack, comm] = count(); }'
Trace method compilation:

Click here to view code image

bpftrace -p $(pgrep -n java) -e 'U:/.../libjvm.so:method__compile__begin {
     printf("compiling: %s\n", str(arg4, arg5)); }'
Trace class loads:

Click here to view code image

bpftrace -p $(pgrep -n java) -e 'U:/.../libjvm.so:class__loaded {
    printf("loaded: %s\n", str(arg0, arg1)); }'
Count object allocation (needs ExtendedDTraceProbes):

Click here to view code image

bpftrace -p $(pgrep -n java) -e 'U:/.../libjvm.so:object__alloc {
    @[str(arg1, arg2)] = count(); }'
12.4 BASH SHELL
The final language example is an interpreted language: the bash shell. Interpreted languages are typically much slower than compiled languages, due to the way they run their own functions to execute each step of the target program. This makes them an uncommon target for performance analysis, since other languages are usually chosen for performance sensitive workloads. BPF tracing may be performed, but the need may be for troubleshooting program errors, rather than finding performance wins.

How interpreted languages are traced is different for each language, reflecting the internals of the software that runs them. This section will show how I approach an unknown interpreted language and determine out how to trace it for the first time: an approach that you can follow for other languages.

The bash readline() function was traced earlier in this chapter, but I have not traced bash in depth beyond that. For this chapter I will determine out how to trace bash function and built-in calls, and develop some tools to automate this. See Table 12-4.

Table 12-4 Bash Shell–Related Tools

Tool

Source

Target

Description

bashfunc

Book

bash

Trace bash function calls

bashfunclat

Book

bash

Trace bash function call latency

As mentioned earlier, how bash is built affects the location of symbols. Here is bash on Ubuntu, showing its dynamic library usage with the ldd(1) tool:

Click here to view code image


$ ldd /bin/bash
        linux-vdso.so.1 (0x00007ffe7197b000)
        libtinfo.so.5 => /lib/x86_64-linux-gnu/libtinfo.so.5 (0x00007f08aeb86000)
        libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f08ae982000)
        libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f08ae591000)
        /lib64/ld-linux-x86-64.so.2 (0x00007f08af0ca000)

The targets to trace are /bin/bash and the shared libraries listed above. As an example of how this can cause differences: on many distributions, bash uses a readline() function from /bin/bash, but some distributions link to libreadline and call it from there.

Preparation
In preparation, I have built the bash software with these steps:

Click here to view code image


CFLAGS=-fno-omit-frame-pointer ./configure
make

This honors the frame pointer register so that I can use frame pointer–based stack walking during my analysis. It also provides a bash binary with local symbol tables, unlike /bin/bash which has been stripped.

Sample Program
The following is a sample bash program I wrote for analysis, welcome.sh:

Click here to view code image


#!/home/bgregg/Build/bash-4.4.18/bash

function welcome {
        echo "Hello, World!"
        echo "Hello, World!"
        echo "Hello, World!"
}

welcome
welcome
welcome
welcome
welcome
welcome
welcome
sleep 60

This begins with the path to my bash build. The program makes seven calls to the “welcome” function, where each function call makes three calls to echo(1) (which I expect is a bash built-in) for a total of 21 echo(1) calls. I choose these numbers hoping they stand out more from other activity while tracing.20

20 It would make this example too long, but I often use 23, a prime number.

12.4.1 Function Counts
Using funccount(8) from BCC, I will guess that the function call is executed by an internal bash function containing the string “func”:

Click here to view code image


# funccount 'p:/home/bgregg/Build/bash-4.4.18/bash:*func*'
Tracing 55 functions for "p:/home/bgregg/Build/bash-4.4.18/bash:*func*"... Hit Ctrl-C
to end.
^C
FUNC                                    COUNT
copy_function_def                           1
sv_funcnest                                 1
dispose_function_def                        1
bind_function                               1
make_function_def                           1
execute_intern_function                     1
init_funcname_var                           1
bind_function_def                           2
dispose_function_def_contents               2
map_over_funcs                              2
copy_function_def_contents                  2
make_func_export_array                      2
restore_funcarray_state                     7
execute_function                            7
find_function_def                           9
make_funcname_visible                      14
execute_builtin_or_function                28
get_funcname                               29
find_function                              31
Detaching...

While tracing, I ran the welcome.sh program, which calls the welcome function seven times. It looks like my guess was good: there were seven calls to restore_funcarray_state() and execute_function(), and the latter sounds most promising, just based on its name.

The name execute_function() gives me an idea: what other calls begin with “execute_”? Checking using funccount(8):

Click here to view code image


# funccount 'p:/home/bgregg/Build/bash-4.4.18/bash:execute_*'
Tracing 29 functions for "p:/home/bgregg/Build/bash-4.4.18/bash:execute_*"... Hit
Ctrl-C to end.
^C
FUNC                                    COUNT
execute_env_file                            1
execute_intern_function                     1
execute_disk_command                        1
execute_function                            7
execute_connection                         14
execute_builtin                            21
execute_command                            23
execute_builtin_or_function                28
execute_simple_command                     29
execute_command_internal                   51
Detaching...

Some more numbers stand out: this has execute_builtin() 21 times, which equals the calls to echo(1). If I want to trace echo(1) and other built-ins, I can start by tracing execute_builtin(). There was also execute_command() called 23 times, which may be the echo(1) calls plus the function declaration plus the sleep(1) call. It sounds like another promising function to trace for understanding bash.

12.4.2 Function Argument Tracing (bashfunc.bt)
Now to trace execute_function() call. I want to know which function, hoping it will show that it is executing the “welcome” function. Hopefully this can be found from one of the arguments. The bash source has (execute_cmd.c):

Click here to view code image


static int
execute_function (var, words, flags, fds_to_close, async, subshell)
     SHELL_VAR *var;
     WORD_LIST *words;
     int flags;
     struct fd_bitmap *fds_to_close;
     int async, subshell;
{
  int return_val, result;
[...]
  if (subshell == 0)
    {
      begin_unwind_frame ("function_calling");
      push_context (var->name, subshell, temporary_env);
[...]

Browsing this source suggests that var, the first argument, is the executed function. It is of type SHELL_VAR, which is struct variable, from variables.h:

Click here to view code image


typedef struct variable {
  char *name;                   /* Symbol that the user types. */
  char *value;                  /* Value that is returned. */
  char *exportstr;              /* String for the environment. */
  sh_var_value_func_t *dynamic_value;   /* Function called to return a ‘dynamic'
                                   value for a variable, like $SECONDS
                                   or $RANDOM. */
  sh_var_assign_func_t *assign_func; /* Function called when this ‘special
                                   variable' is assigned a value in
                                   bind_variable. */
  int attributes;               /* export, readonly, array, invisible... */
  int context;                  /* Which context this variable belongs to. */
} SHELL_VAR;

char *’s are straightforward to trace. Let’s look at the name member using bpftrace. I can either #include this header or declare the struct directly in bpftrace. I’ll show both, starting with the header include. Here is bashfunc.bt21:

21 Origin: I created this for this book on 9-Feb-2019.

Click here to view code image


#!/usr/local/bin/bpftrace

#include "/home/bgregg/Build/bash-4.4.18/variables.h"

uprobe:/home/bgregg/Build/bash-4.4.18/bash:execute_function
{
        $var = (struct variable *)arg0;
        printf("function: %s\n", str($var->name));
}

Running this:

Click here to view code image


# ./bashfunc.bt
/home/bgregg/Build/bash-4.4.18/variables.h:24:10: fatal error: 'stdc.h' file not found
Attaching 1 probe...
function: welcome
function: welcome
function: welcome
function: welcome
function: welcome
function: welcome
function: welcome
^C

It worked! I can now trace bash function calls.

It also printed a warning about another missing header file. I’ll show the second approach, where the struct is declared directly. In fact, since I only need the first member, I’ll only declare that member and call it a “partial” struct.

Click here to view code image


#!/usr/local/bin/bpftrace

struct variable_partial {
        char *name;
};

uprobe:/home/bgregg/Build/bash-4.4.18/bash:execute_function
{
        $var = (struct variable_partial *)arg0;
        printf("function: %s\n", str($var->name));
}

Using this version of bashfunc.bt:


# ./bashfunc.bt
Attaching 1 probe...
function: welcome
function: welcome
function: welcome
function: welcome
function: welcome
function: welcome
function: welcome
^C

This works, without the error or the requirement for the bash source.

Note that uprobes are an unstable interface, so this program may stop working if bash changes its function names and arguments.

12.4.3 Function Latency (bashfunclat.bt)
Now that I can trace function calls, let’s look at function latency: the duration of the function.

To start with, I modified welcome.sh so that the function was:


function welcome {
        echo "Hello, World!"
        sleep 0.3
}

This provides a known latency for the function call: 0.3 seconds.

Now I’ll check whether execute_function() waits for the shell function to complete by measuring its latency using funclatency(8) from BCC:

Click here to view code image


# funclatency -m /home/bgregg/Build/bash-4.4.18/bash:execute_function
Tracing 1 functions for "/home/bgregg/Build/bash-4.4.18/bash:execute_function"... Hit
Ctrl-C to end.
^C

Function = execute_function [7083]
     msecs               : count     distribution
         0 -> 1          : 0        |                                        |
         2 -> 3          : 0        |                                        |
         4 -> 7          : 0        |                                        |
         8 -> 15         : 0        |                                        |
        16 -> 31         : 0        |                                        |
        32 -> 63         : 0        |                                        |
        64 -> 127        : 0        |                                        |
       128 -> 255        : 0        |                                        |
       256 -> 511        : 7        |****************************************|
Detaching...

Its latency was in the 256 to 511 millisecond bucket, which matches our known latency. It looks like I can simply time this function for the latency of the shell function.

Turning this into a tool so that shell function latency can be printed as a histogram by shell function name, bashfunclat.bt22:

22 Origin: I created this for this book on 9-Feb-2019.

Click here to view code image


#!/usr/local/bin/bpftrace

struct variable_partial {
        char *name;
};

BEGIN
{
        printf("Tracing bash function latency, Ctrl-C to end.\n");
}

uprobe:/home/bgregg/Build/bash-4.4.18/bash:execute_function
{
        $var = (struct variable_partial *)arg0;
        @name[tid] = $var->name;
        @start[tid] = nsecs;
}

uretprobe:/home/bgregg/Build/bash-4.4.18/bash:execute_function
/@start[tid]/
{
        @ms[str(@name[tid])] = hist((nsecs - @start[tid]) / 1000000);
        delete(@name[tid]);
        delete(@start[tid]);
}

This saves a pointer to a function name, and the timestamp, on the uprobe. On the uretprobe, it fetches the name and starting timestamp for creating the histogram.

Output:

Click here to view code image


# ./bashfunclat.bt
Attaching 3 probes...
Tracing bash function latency, Ctrl-C to end.
^C

@ms[welcome]:
[256, 512)             7 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@|

This works. This latency could be presented in different ways if desired: per event or as a linear histogram.

12.4.4 /bin/bash
Up until now, tracing bash has been so straightforward that I started worrying it wasn’t representative of the gritty debugging adventures one normally encounters when tracing interpreters. But I needed to look no further than the default /bin/bash to share such an adventure. These earlier tools have instrumented my own build of bash, which includes the local symbol table and the frame pointer. I modified them and the welcome.sh program to use /bin/bash instead, and found that the BPF tools I wrote no longer worked.

Back to square one. Here’s counting function calls containing “func” in /bin/bash:

Click here to view code image


# funccount 'p:/bin/bash:*func*'
Tracing 36 functions for "p:/bin/bash:*func*"... Hit Ctrl-C to end.
^C
FUNC                                    COUNT
copy_function_def                           1
sv_funcnest                                 1
dispose_function_def                        1
bind_function                               1
make_function_def                           1
bind_function_def                           2
dispose_function_def_contents               2
map_over_funcs                              2
copy_function_def_contents                  2
restore_funcarray_state                     7
find_function_def                           9
make_funcname_visible                      14
find_function                              32
Detaching...

The execute_function() symbol is no longer available. Here’s readelf(1) and file(1) highlighting our problem:

Click here to view code image


$ readelf --syms --dyn-syms /home/bgregg/Build/bash-4.4.18/bash
[...]
  2324: 000000000004cc49   195 FUNC    GLOBAL DEFAULT   14 restore_funcarray_state
[...]
   298: 000000000004cd0c  2326 FUNC    LOCAL  DEFAULT   14 execute_function
[...]
$ file /bin/bash /home/bgregg/Build/bash-4.4.18/bash
/bin/bash:                           ELF 64-bit LSB ..., stripped
/home/bgregg/Build/bash-4.4.18/bash: ELF 64-bit LSB ..., not stripped

execute_function() is a local symbol, and those have been stripped from /bin/bash to reduce the file size.

Fortunately, I still have a lead: the funccount(8) output showed that restore_funcarray_state() was called seven times, equal to our known workload. To check if it is related to function calls, I’ll use stackcount(8) from BCC to show its stack trace:

Click here to view code image


# stackcount -P /bin/bash:restore_funcarray_state
Tracing 1 functions for "/bin/bash:restore_funcarray_state"... Hit Ctrl-C to end.
^C
  [unknown]
  [unknown]
    welcome0.sh [8514]
    7

Detaching...

The stack is broken: I wanted to include this to show what /bin/bash stacks look like by default. It’s one of the reasons I compiled my own bash with frame pointers. Switching to that to investigate this function:

Click here to view code image


# stackcount -P /home/bgregg/Build/bash-4.4.18/bash:restore_funcarray_state
Tracing 1 functions for
"/home/bgregg/Build/bash-4.4.18/bash:restore_funcarray_state"... Hit Ctrl-C to end.
^C
  restore_funcarray_state
  without_interrupts
  run_unwind_frame
  execute_function
  execute_builtin_or_function
  execute_simple_command
  execute_command_internal
  execute_command
  reader_loop
  main
  __libc_start_main
  [unknown]
    welcome.sh [8542]
    7

Detaching...

This shows that restore_funcarray_state() is called as a child of execute_function(), so it is indeed related to the shell function calls.

The function is in execute_cmd.c:


void
restore_funcarray_state (fa)
     struct func_array_state *fa;
{

The struct func_array_state is, from execute_cmd.h:


struct func_array_state
  {
    ARRAY *funcname_a;
    SHELL_VAR *funcname_v;
    ARRAY *source_a;
    SHELL_VAR *source_v;
    ARRAY *lineno_a;
    SHELL_VAR *lineno_v;
  };

This seems to be used for creating local contexts while running functions. I guessed that funcname_a or funcname_v might contain what I am after: the name of the called function, so I declared structs and printed strings in a similar fashion to my earlier bashfunc.bt to find it. But I was unable to find the function name.

There are many paths forward, and given that I am using an unstable interface (uprobes), there isn’t necessarily a right way to do this (the right way is USDT). Example next steps:

funccount(8) also showed a few other interesting sounding functions: find_function(), make_funcname_visible(), and find_function_def(), all called more times than our known function. Perhaps the function name is in their arguments or return value, and I can cache it for later lookup in restore_funcarray_state().

stackcount(8) showed higher level functions: Are any of these symbols still present in /bin/bash, and may they provide another path to tracing the function?

Here’s a look at that second approach, by checking what “execute” functions are visible in /bin/bash:

Click here to view code image


# funccount '/bin/bash:execute_*'
Tracing 4 functions for "/bin/bash:execute_*"... Hit Ctrl-C to end.
^C
FUNC                                    COUNT
execute_command                            24
execute_command_internal                   52
Detaching...

The source code shows that execute_command() runs many things, including functions, and they can be identified by a type number from the first argument. This would be one path forward: filter for just function calls, and explore the other arguments to find the function name.

I found the first approach worked immediately: find_function() has the name as its argument, which I could cache for later lookup. An updated bashfunc.bt:

Click here to view code image


#!/usr/local/bin/bpftrace

uprobe:/bin/bash:find_function_def
{
        @currfunc[tid] = arg0;
}

uprobe:/bin/bash:restore_funcarray_state
{
        printf("function: %s\n", str(@currfunc[tid]));
        delete(@currfunc[tid]);
}

Output:


# bashfunc.bt
Attaching 2 probes...
function: welcome
function: welcome
function: welcome
function: welcome
function: welcome
function: welcome
function: welcome

While this works, this is tied to this version of bash and its implementation.

12.4.5 /bin/bash USDT
For tracing bash not to run into issues as bash internals change, USDT probes can be added to the code. For example, imagine USDT probes with the following format:

Click here to view code image


bash:execute__function__entry(char *name, char **args, char *file, int linenum)
bash:execute__function__return(char *name, int retval, char *file, int linenum)

Then printing the function name, as well as showing the arguments, return value, latency, source file, and line number, would all be straightforward.

As an example of instrumenting the shell, USDT probes were added to the Bourne shell for Solaris systems [139], with the following probe definitions:

Click here to view code image


provider sh {
    probe function-entry(file, function, lineno);
    probe function-return(file, function, rval);
    probe builtin-entry(file, function, lineno);
    probe builtin-return(file, function, rval);
    probe command-entry(file, function, lineno);
    probe command-return(file, function, rval);
    probe script-start(file);
    probe script-done(file, rval);
    probe subshell-entry(file, childpid);
    probe subshell-return(file, rval);
    probe line(file, lineno);
    probe variable-set(file, variable, value);
    probe variable-unset(file, variable);
};

This should also provide ideas for future bash shell USDT probes.

12.4.6 bash One-Liners
These sections show BCC and bpftrace one-liners for bash shell analysis.

BCC
Count execution types (requires symbols):

Click here to view code image

funccount '/bin/bash:execute_*'
Trace interactive command input:

Click here to view code image

trace 'r:/bin/bash:readline "%s", retval'
bpftrace
Count execution types (requires symbols):

Click here to view code image

bpftrace -e 'uprobe:/bin/bash:execute_* { @[probe] = count(); }'
Trace interactive command input:

Click here to view code image

bpftrace -e 'ur:/bin/bash:readline { printf("read: %s\n", str(retval)); }'
12.5 OTHER LANGUAGES
There are many more programming languages and runtimes, and more will be created. To instrument them, first identify how they are implemented: are they compiled into binaries, JIT compiled, interpreted, or some combination of these? Studying the relevant previous section on C (for compiled), Java (for JIT compiled), and the bash shell (for interpreted), will give you a head start on the approach and challenges involved.

On this book’s website [140] I will link to articles about using BPF to instrument other languages as they are written. The following are tips for other languages that I have previously traced using BPF: JavaScript (Node.js), C++, and GoLang.

12.5.1 JavaScript (Node.js)
BPF tracing is similar to Java. The current runtime used by Node.js is v8, developed by Google for the Chrome web browser. v8 can run Java functions interpreted, or JIT compile them for native execution. The runtime also manages memory, and has a garbage collection routine.

The following summarizes Node.js USDT probes, stack walking, symbols, and function tracing.

USDT Probes
There are built-in USDT probes and a node-usdt library for adding dynamic USDT probes to the JavaScript code [141]. The Linux distribution currently does not ship with the USDT probes enabled: to use them, you must recompile Node.js from source with the --with-dtrace option. Example steps:

Click here to view code image


$ wget https://nodejs.org/dist/v12.4.0/node-v12.4.0.tar.gz
$ tar xf node-v12.4.0.tar.gz
$ cd node-v12.4.0
$ ./configure --with-dtrace
$ make

Listing USDT probes using bpftrace:

Click here to view code image


# bpftrace -l 'usdt:/usr/local/bin/node'
usdt:/usr/local/bin/node:node:gc__start
usdt:/usr/local/bin/node:node:gc__done
usdt:/usr/local/bin/node:node:http__server__response
usdt:/usr/local/bin/node:node:net__stream__end
usdt:/usr/local/bin/node:node:net__server__connection
usdt:/usr/local/bin/node:node:http__client__response
usdt:/usr/local/bin/node:node:http__client__request
usdt:/usr/local/bin/node:node:http__server__request
[...]

These show USDT probes for garbage collection, HTTP requests, and network events. For more on Node.js USDT, see my blog post “Linux bcc/BPF Node.js USDT Tracing” [142].

Stack Walking
Stack walking should work (frame pointer based), although translation of JITed JavaScript functions into symbols requires an extra step (explained next).

Symbols
As with Java, supplemental symbol files in /tmp are required to translate JITted function addresses to function names. If you are using Node.js v10.x or above, there are two ways to create these symbol files:

Using the v8 flags --perf_basic_prof or --perf_basic_prof_only_functions. These will create a rolling symbol logs that are continually updated, unlike Java which dumps snapshots of the symbol state. Since these rolling logs cannot be disabled while the process is running, over time it can lead to extremely large map files (Gbytes) containing mostly stale symbols.

The linux-perf module [143], which is a combination of how the flags work and how Java’s perf-map-agent work: it will capture all functions on the heap and write to the map file, and then it will continue to write to the file while new functions are compiled. It’s possible to start capturing new functions at any time. This method is recommended.

Using both approaches, I’ve needed to post-process the supplemental symbol files to remove stale entries.23

23 You might assume that tools like perf(1) would read the symbol file backwards and use the most recent mappings for a given address. I’ve found that not to be the case, and an older mapping is used when there is a newer mapping in the log. This is why I’ve needed to post process these logs: only retaining the newest mappings for addresses.

Another recommended flag is --interpreted-frames-native-stack (also available for Node.js v10.x and above). With this flag, Linux perf and BPF tools will be able to translate interpreted JavaScript functions into their actual names (instead of showing “Interpreter” frames on the stack).

A common use case that requires external Node.js symbols is CPU profiling and CPU flame graphs [144]. These can be generated using perf(1) or BPF tools.

Function Tracing
There are not currently USDT probes for tracing JavaScript functions, and due to V8’s architecture, it would be challenging to add them. Even if someone adds it, as I discussed with Java, the overhead can be extreme: slowing applications by 10x while in use.

The JavaScript functions are visible in user-level stack traces, which can be collected on kernel events such as timed sampling, disk I/O, TCP events, and context switches. This provides many insights into Node.js performance, including with function context, without the penalty of tracing functions directly.

12.5.2 C++
C++ can be traced much the same as C, with uprobes for function entry, uprobes for function returns, and frame pointer–based stacks if the compiler has honored the frame pointer. There are a couple of differences:

Symbol names are C++ signatures. Instead of ClassLoader::initialize(), that symbol may be traced as _ZN11ClassLoader10initializeEv. The BCC and bpftrace tools use demangling when printing symbols.

Function arguments may not accommodate the processor ABI for support of objects and the self object.

Counting function calls, measuring function latency, and showing stack traces should all be straightforward. It may help to use wildcards to match function names from their signatures when possible (e.g., uprobe:/path:*ClassLoader*initialize*).

Inspecting arguments will require more work. Sometimes they are simply offset by one to accommodate a self object as the first argument. Strings are often not native C strings, but C++ objects, and can’t simply be dereferenced. Objects need structs to be declared in the BPF program so that BPF can dereference members.

This may all become much easier with BTF, introduced in Chapter 2, which may provide the locations of arguments and object members.

12.5.3 Golang
Golang compiles to binaries, and tracing them is similar to tracing C binaries, but there are some important differences with its function calling conventions, goroutines, and dynamic stack management. Due to the latter, uretprobes are currently unsafe to use on Golang as they can crash the target program. There are also differences between the compiler used: by default Go gc emits statically linked binaries, whereas gccgo emits dynamically linked binaries. These topics are discussed in the following sections.

Note that there are already other ways to debug and trace Go programs that you should be aware of, including gdb’s Go runtime support, the go execution tracer [145], and GODEBUG with gctrace and schedtrace.

Stack Walking and Symbols
Both Go gc and gccgo honor the frame pointer by default (Go since version 1.7) and include symbols in the resulting binaries. This means that stack traces that include Go functions can always be collected, from either user- or kernel-level events, and profiling via timed sampling will also work immediately.

Function Entry Tracing
The entry to functions can be traced with uprobes. For example, using bpftrace to count function calls that begin with “fmt” in a “Hello, World!” Golang program named “hello”, which was compiled using Go gc:

Click here to view code image


# bpftrace -e 'uprobe:/home/bgregg/hello:fmt* { @[probe] = count(); }'
Attaching 42 probes...
^C

@[uprobe:/home/bgregg/hello:fmt.(*fmt).fmt_s]: 1
@[uprobe:/home/bgregg/hello:fmt.newPrinter]: 1
@[uprobe:/home/bgregg/hello:fmt.Fprintln]: 1
@[uprobe:/home/bgregg/hello:fmt.(*pp).fmtString]: 1
@[uprobe:/home/bgregg/hello:fmt.glob..func1]: 1
@[uprobe:/home/bgregg/hello:fmt.(*pp).printArg]: 1
@[uprobe:/home/bgregg/hello:fmt.(*pp).free]: 1
@[uprobe:/home/bgregg/hello:fmt.Println]: 1
@[uprobe:/home/bgregg/hello:fmt.init]: 1
@[uprobe:/home/bgregg/hello:fmt.(*pp).doPrintln]: 1
@[uprobe:/home/bgregg/hello:fmt.(*fmt).padString]: 1
@[uprobe:/home/bgregg/hello:fmt.(*fmt).truncate]: 1

While tracing I ran the hello program once. The output shows that various fmt functions were called once, including fmt.Println(), which I suspect is printing “Hello, World!”.

Now counting the same functions from a gccgo binary. In this case, those functions are in the libgo library, and that location must be traced:

Click here to view code image


# bpftrace -e 'uprobe:/usr/lib/x86_64-linux-gnu/libgo.so.13:fmt* { @[probe] =
count(); }'
Attaching 143 probes...
^C

@[uprobe:/usr/lib/x86_64-linux-gnu/libgo.so.13:fmt.fmt.clearflags]: 1
@[uprobe:/usr/lib/x86_64-linux-gnu/libgo.so.13:fmt.fmt.truncate]: 1
@[uprobe:/usr/lib/x86_64-linux-gnu/libgo.so.13:fmt.Println]: 1
@[uprobe:/usr/lib/x86_64-linux-gnu/libgo.so.13:fmt.newPrinter]: 1
@[uprobe:/usr/lib/x86_64-linux-gnu/libgo.so.13:fmt.buffer.WriteByte]: 1
@[uprobe:/usr/lib/x86_64-linux-gnu/libgo.so.13:fmt.pp.printArg]: 1
@[uprobe:/usr/lib/x86_64-linux-gnu/libgo.so.13:fmt.pp.fmtString]: 1
@[uprobe:/usr/lib/x86_64-linux-gnu/libgo.so.13:fmt.fmt.fmt_s]: 1
@[uprobe:/usr/lib/x86_64-linux-gnu/libgo.so.13:fmt.pp.free]: 1
@[uprobe:/usr/lib/x86_64-linux-gnu/libgo.so.13:fmt.fmt.init]: 1
@[uprobe:/usr/lib/x86_64-linux-gnu/libgo.so.13:fmt.buffer.WriteString]: 1

@[uprobe:/usr/lib/x86_64-linux-gnu/libgo.so.13:fmt.pp.doPrintln]: 1
@[uprobe:/usr/lib/x86_64-linux-gnu/libgo.so.13:fmt.fmt.padString]: 1
@[uprobe:/usr/lib/x86_64-linux-gnu/libgo.so.13:fmt.Fprintln]: 1
@[uprobe:/usr/lib/x86_64-linux-gnu/libgo.so.13:fmt..import]: 1
@[uprobe:/usr/lib/x86_64-linux-gnu/libgo.so.13:fmt..go..func1]: 1

The naming convention for the functions is a little different. The output includes fmt.Println(), as seen earlier.

These functions can also be counted using the funccount(8) tool from BCC. The commands for the Go gc version and then the gccgo version are:

Click here to view code image


funccount '/home/bgregg/hello:fmt.*'
funccount 'go:fmt.*'

Function Entry Arguments
Go’s gc compiler and gccgo use different function-calling conventions: gccgo uses the standard AMD64 ABI, whereas Go’s gc compiler uses Plan 9’s stack-passing approach. This means that fetching function arguments differs: with gccgo, the usual approach (e.g., via bpftrace arg0...argN) will work, but it will not with Go gc: custom code will need to be used to get it from the stack (see [146][147]).

For example, consider the add(x int, y int) function from the Golang tutorial [148], which is called with the arguments 42 and 13. To instrument its arguments on a gccgo binary:

Click here to view code image


# bpftrace -e 'uprobe:/home/bgregg/func:main*add { printf("%d %d\n", arg0, arg1); }'
Attaching 1 probe...
42 13

The arg0 and arg1 built-ins work. Note that I needed to compile using gccgo -O0 so that the add() function wasn’t inlined by the compiler.

Now instrumenting its arguments on a Go gc binary:

Click here to view code image


# bpftrace -e 'uprobe:/home/bgregg/Lang/go/func:main*add { printf("%d %d\n",
    *(reg("sp") + 8), *(reg("sp") + 16)); }'
Attaching 1 probe...
42 13

This time the arguments needed to be read from their offsets the stack, accessed via reg(“sp”). A future version of bpftrace may support these as aliases, such as sarg0, sarg1 [149], short for “stack argument”. Note that I needed to compile this using go build -gcflags '-N -l' ... so that the add() function wasn’t inlined by the compiler.

Function Returns
Unfortunately, uretprobe tracing is not safe with the current implementation of uretprobes. The Go compiler can modify the stack at any time, unaware that the kernel has added a uretprobe trampoline handler to the stack.24 This can cause memory corruption: once the uretprobe is deactivated, the kernel will return those bytes to normal, however, those bytes may now contain other Golang program data, and will be corrupted by the kernel. This can cause Golang to crash (if you are lucky) or continue running with corrupt data (if you are unlucky).

24 Thanks Suresh Kumar for helping explain this problem; see his comment in [146].

Gianluca Borello has experimented with a solution that involves using uprobes on the return locations of functions rather than uretprobes. This involves disassembling a function to find the return points, and then placing a uretprobe on them (see [150]).

Another problem is goroutines: these can be scheduled between different OS threads as they are running, so the usual method of timing function latency by using a timestamp keyed on thread ID (e.g., with bpftrace: @start[tid] = nsecs) is no longer reliable.

USDT
The Salp library provides dynamic USDT probes via libstapsdt [151]. This allows static probe points to be placed in your Go code.

12.6 SUMMARY
Whether your programming language of interest is compiled, JIT compiled, or interpreted, there is likely a way to analyze it with BPF. In this chapter I discussed these three types and then showed how to trace an example from each: C, Java, and the bash shell. With tracing it should be possible to examine their function or method calls, examining their arguments and return value, function or method latency, and also show stack traces from other events. Tips for other languages were also included for JavaScript, C++, and Golang.

CopyAdd HighlightAdd Note
back to top
